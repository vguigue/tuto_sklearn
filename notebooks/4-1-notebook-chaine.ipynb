{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "219aedad",
   "metadata": {},
   "source": [
    "# Chaine de traitements\n",
    "\n",
    "[Version 2025: pour plus de clarté, le TP est divisé en 3]\n",
    "\n",
    "Une chaine de traitements est composée de différents maillons\n",
    "\n",
    "<img src=\"fig/chaine2.png\">\n",
    "\n",
    "> L'impact des pré-traitements sur la performance finale est souvent très important\n",
    "\n",
    "Nous allons donc étudier les pré-traitement les plus classiques et la manière de les implémenter proprement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120d421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b6fffc",
   "metadata": {},
   "source": [
    "# A. Transformation des variables de description\n",
    "\n",
    "Les données brutes sont souvent incomplètes et bruitées, parfois trop spécifiques etc...\n",
    "L'exploitation de ces informations requière leur transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558ea75b",
   "metadata": {},
   "source": [
    "\n",
    "## A.1. Enrichissement et transformation des données\n",
    "\n",
    "### A.1.1. Encodage des variables discrètes\n",
    "\n",
    "Les variables descriptives sont souvent discrètes... Or les approches de machine learning ne savent pas gérer ces informations là (sauf certains arbres).\n",
    "\n",
    "1. Charger des données discrètes   \n",
    "    * prédiction de récidive de cancer\n",
    "2. Afficher les 3 premières lignes (et bien comprendre qu'on a un problème par rapport aux données manipulées jusqu'ici)\n",
    "3. Transformer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f5e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération de données discrètes\n",
    "import pandas as pd\n",
    "\n",
    "filename = \"data/breast-cancer.csv\"\n",
    "data = pd.read_csv(filename, header=None).values\n",
    "\n",
    "Xbrut = data[:,:-1]\n",
    "Ybrut = data[:,-1:]\n",
    "\n",
    "print(Xbrut[:3,:], Ybrut[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1172b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation (=prise de contact)\n",
    "# Sur 4 variables (arbitrairement)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "n = 4\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1,n,i+1)\n",
    "    ax.hist(Xbrut[:,i], bins = len(np.unique(Xbrut[:,i])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5763ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation des données\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "enc.fit(Xbrut)\n",
    "\n",
    "print(\"Catégories: \\n\",enc.categories_)\n",
    "X = enc.transform(Xbrut) # transformation des X\n",
    "\n",
    "enc2 = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "Y = enc2.fit_transform(Ybrut)[:,0] # même opération (tout en une ligne) pour les Y\n",
    "\n",
    "print(\"Echantillon: \\n\",X[:3,:], Y[:3])\n",
    "\n",
    "print(\"Comparaison des dimensions: \\n\",Xbrut.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec14294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse et performances\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# définition du modèle\n",
    "mod = SVC(kernel=\"linear\")\n",
    "n_fold = 5\n",
    "scores = cross_val_score(mod, X, Y, cv=n_fold, scoring='accuracy') # tout est caché dedans :)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1eb67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On sait maintenant qu'il faut se méfier de l'accuracy dans les cas déséquilibré...\n",
    "# vérification sur la balance des étiquettes \n",
    "print(np.histogram(Y,2))\n",
    "\n",
    "# calcul du score f1\n",
    "scores = cross_val_score(mod, X, Y, cv=n_fold, scoring='f1') # tout est caché dedans :)\n",
    "print(scores) # ça va"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbc78ca",
   "metadata": {},
   "source": [
    "### A.1.2 Création de nouvelles variables\n",
    "\n",
    "Sur l'exemples de l'échiquier, si on ajoute un descripteur qui change de valeur sur le modulo 2 de la coordonnées des points... Le problème devient (presque) séparable linéairement.\n",
    "\n",
    "1. On tente de séparer le problème de base\n",
    "1. On ajoute les variables et on recommence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce170125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération des données\n",
    "centers = [[float(i),float(j)] for i in range(5) for j in range(5)]\n",
    "print(centers)\n",
    "clusters_std = 0.2\n",
    "X, y = make_blobs(n_samples=100, centers=centers, cluster_std=clusters_std,  n_features=2,   random_state=0)\n",
    "y = (y % 2)*2 - 1 # chaque centre = 1 classe => Echiquier binaire\n",
    "\n",
    "print(X.shape)\n",
    "plt.figure()\n",
    "plt.scatter(X[:,0], X[:,1], c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df32613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction d'un classifieur linéaire\n",
    "\n",
    "mod = svm.SVC(kernel=\"linear\")\n",
    "mod.fit(X,y)\n",
    "\n",
    "sc = cross_val_score(mod,X,y)\n",
    "print(\"Scores de classification (val. croisée x5, mod linéaire): \", sc)\n",
    "\n",
    "# => Les données ne sont pas séparable linéairemnet !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad3d957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajout de variables (très utiles)\n",
    "\n",
    "Xi = np.reshape([(np.floor(i)%2)*2-1 for i in X[:,0]+0.5], (-1,1))\n",
    "Xj = np.reshape([(np.floor(i)%2)*2-1 for i in X[:,1]+0.5], (-1,1))\n",
    "\n",
    "Xe = np.concatenate((X,Xi,Xj), axis = 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(Xe[:12,:])\n",
    "# plt.savefig(\"fig/checkers_Xe.pdf\")\n",
    "\n",
    "sc = cross_val_score(mod,Xe,y)\n",
    "print(\"Scores de classification (val. croisée x5, mod linéaire + données enrichies):\", sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e0f192",
   "metadata": {},
   "source": [
    "### A.1.3 Discrétisation de variables continues\n",
    "\n",
    "Il est parfois difficile de tirer parti des informations continues et plus simple de créer des variables encodant directement l'appartenance à un segment.\n",
    "\n",
    "e.g. : données étalées entre 1 et 10, avec:\n",
    "* un peu de points uniformément répartis entre 1 et 5\n",
    "* beaucoup de points centrés en 7.5 avec une faible dispersion\n",
    "* beaucoup de points centrés en 9 avec une faible dispersion\n",
    "\n",
    "A peu près de la forme suivante:\n",
    "<img src=\"fig/distrib-pts2.png\">\n",
    "\n",
    "$\\Rightarrow$ ce type de distribution destabilise les approches de ML\n",
    "\n",
    "1. La fonction qui permet de faire ça est: `KBinsDiscretizer`\n",
    "2. Génerer des données et tester cette fonction\n",
    "3. [OPT] Réfléchir au pont entre modèle linéaire et arbres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d444e0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# générer des données 1D \n",
    "###  TODO  ###\n",
    "\n",
    "# tester la fonction et afficher la matrice créée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997fca88",
   "metadata": {},
   "source": [
    "## A.2. Normalisation des données (par colonne)\n",
    "\n",
    "Soit des données tabulaires classiques:\n",
    "$$X = \\begin{pmatrix}  x_{11}& x_{12} &  \\ldots & x_{1d}  \\\\\n",
    "x_{21}& x_{22} & \\ldots & x_{2d} \\\\\n",
    "\\vdots& \\vdots & \\ddots &\\vdots \\\\\n",
    "x_{n1}& x_{n2} & \\ldots & x_{nd}  \\\\\n",
    "\\end{pmatrix} ,\\qquad\n",
    "Y = \\begin{pmatrix}  y_{1} \\\\\n",
    "y_{2}\\\\\n",
    "\\vdots\\\\\n",
    "y_{n} \\\\\n",
    "\\end{pmatrix} ,\\qquad y_i\\in \\mathcal Y\n",
    "$$\n",
    "\n",
    "Dans la plupart des cas, le problème vient des $X_j$ :\n",
    "\n",
    "* qui ne sont pas codés dans les mêmes échelles. e.g. colonne $i$ en $10^{-5}$, colonne $j$ en $10^{-9}$ \n",
    "* qui ont simplement un biais trop important, e.g. valeur entre $1050$ et $1070$\n",
    "\n",
    "Les algorithmes de ML sont souvent destabilités par ces écarts de valeur. Il faut normaliser pour obtenir de bonnes performances\n",
    "\n",
    "On utilise presque tout le temps une normlisation standard gaussienne consistant à centrer réduire les $X_j \\Rightarrow \\tilde{X}_j \\sim \\mathcal N(0,1)$.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcb3dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = \"data/winequality-red.csv\"\n",
    "data = pd.read_csv(filename)\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f3a7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison des performances avec et sans normalisation\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = data.values[:,:-1]\n",
    "Y = data.values[:,-1]\n",
    "# remise en forme des Y entre 0 et nClasses\n",
    "val = np.unique(Y)\n",
    "transf = dict(zip(val,np.arange(len(val)))) # mapping [x,y,z] => [0,1,2]\n",
    "Y = np.vectorize(transf.get)(Y)             # application de la transformation\n",
    "\n",
    "mod = SVC()\n",
    "sc = cross_val_score( mod, X, Y, scoring='accuracy')\n",
    "\n",
    "print(\"Scores \",sc,sc.mean())\n",
    "\n",
    "# normalisation des données\n",
    "scal = StandardScaler()\n",
    "\n",
    "# 1. Appliquer la transformation (cf doc)\n",
    "\n",
    "# 2. Calculer la performance\n",
    "\n",
    "###  TODO  ###\n",
    "\n",
    "print(\"Scores sur données normalisées \",sc,sc.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab3ea52",
   "metadata": {},
   "source": [
    "**Question d'ouverture**\n",
    "\n",
    "L'impact de la normalisation est-il le même sur tous les classifieurs?\n",
    "\n",
    "Non, évidemment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb70ea5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb # !pip install xgboost # en cas de besoin\n",
    "\n",
    "bst = xgb.XGBClassifier()\n",
    "sc = cross_val_score( bst, X, Y, scoring='accuracy')\n",
    "print(\"xgboost : \",sc, sc.mean())\n",
    "\n",
    "sc = cross_val_score( bst, Xn, Y, scoring='accuracy')\n",
    "print(\"xgboost (normalisé): \",sc, sc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0ed1eb",
   "metadata": {},
   "source": [
    "## A.3. Normalisation par individu\n",
    "\n",
    "Sur certaines applications spécifiques comme la classification de signaux ou les données textuelles, on normalise les individus afin de les rendre comparables\n",
    "\n",
    "* par défaut, un texte de 100 mots n'est pas comparable avec un texte de 1000 mots\n",
    "* les log à la station chatelet dans une journée de semaine ne sont pas comparables avec un week-end\n",
    "\n",
    "Les deux normalisations les plus connues (et utilisées) sont:\n",
    "\n",
    "1. La normalisation probabiliste (les variables de l'individu somme à 1), on fait une hypothèse multinomiale sur les variables\n",
    "    * pour le texte notamment\n",
    "1. La normalisation min-max => 0-1\n",
    "    * souvent pour les signaux\n",
    "    * Evidemment, en fonction de l'application visée, ça peut être utile ou au contraire néfaste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05264b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = \"data/Beef_TRAIN.tsv\"\n",
    "data = pd.read_csv(filename, header=None, sep='\\t')\n",
    "\n",
    "print(np.unique(data.values[:,0], return_counts=True))\n",
    "\n",
    "data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89072ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X = data.values[:,1:]\n",
    "Y = data.values[:,0]\n",
    "# remise en forme des Y entre 0 et nClasses\n",
    "val = np.unique(Y)\n",
    "transf = dict(zip(val,np.arange(len(val)))) # mapping [x,y,z] => [0,1,2]\n",
    "Y = np.vectorize(transf.get)(Y)             # application de la transformation\n",
    "\n",
    "mod = SVC()\n",
    "sc = cross_val_score( mod, X, Y, scoring='accuracy')\n",
    "\n",
    "print(\"Scores \",sc,sc.mean())\n",
    "\n",
    "# normalisation des données\n",
    "scal = MinMaxScaler()\n",
    "#scal = StandardScaler() # vous pouvez switcher pour voir...\n",
    "Xn = scal.fit_transform(X)\n",
    "sc = cross_val_score( mod, Xn, Y, scoring='accuracy')\n",
    "\n",
    "print(\"Scores sur données normalisées \",sc,sc.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9711d4e1",
   "metadata": {},
   "source": [
    "# Construction du sujet à partir de la correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0444c126",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  TODO )\",\" TODO \",\\\n",
    "    txt, flags=re.DOTALL))\n",
    "f2.close()\n",
    "\n",
    "### </CORRECTION> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7583764",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyth-torch-numpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
