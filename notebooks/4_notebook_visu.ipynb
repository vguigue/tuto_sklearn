{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réduction de dimensionnalité: visualisation & débruitage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des librairies standards:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import pickle as pkl\n",
    "import math\n",
    "%matplotlib inline  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation de données\n",
    "\n",
    "Nous proposons une série d'expériences pour appréhender la visualisation de données et la réduction de la dimensionnalité:\n",
    "\n",
    "1. Comprendre la signification des valeurs propres et vecteurs propres sur les données gaussiennes sur lesquelles nous avons travaillé jusqu'ici\n",
    "1. Générer un jeu de données jouet en 3D puis réduire la dimensionnalité\n",
    "1. Appliquer cette réduction de dimension sur les données USPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# données équilibrées (cas simple pour démarrer)\n",
    "centers = [[-1,-1], [1,1]]\n",
    "clusters_std = [1.,1.]\n",
    "N = 100\n",
    "X, Y = make_blobs(n_samples=N, centers=centers, cluster_std=clusters_std,  n_features=2,   random_state=0) # 100 pts, 2classes, 2dim \n",
    "\n",
    "\n",
    "plt.figure(facecolor='white')\n",
    "plt.scatter(X[:,0],X[:,1],c=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> EXO </span> Avant de lancer du code, répondez aux questions suivantes:\n",
    "- Combien y a-t-il de vecteurs propres et de valeurs propres dans ce problème?\n",
    "- Quel axe de plus forte variance est préssenti?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Vérifions maintenant avec du code.\n",
    "L'idée est d'appliquer ```np.linalg.eig``` sur la matrice de correlation $X^T X$ et d'afficher les sorties pour les comprendre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des valeurs propres et vecteurs propres & affichage:\n",
    "\n",
    "#  TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracer les vecteurs propres, à partir de (0,0) sur le scatter des points\n",
    "# A l'aide de la commande plt.text, vous pouvez rajouter la \"force\" des axes si vous voulez\n",
    "\n",
    "\n",
    "#  TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check:\n",
    "Vous devez obtenir\n",
    "\n",
    "<img src=\"fig/acp.png\">\n",
    "\n",
    "On voit bien la principale direction de variance (associée à la plus grande valeur propre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réduction de données 2D => 1D\n",
    "\n",
    "Dans une logique de réduction de dimensionnalité, on souhaite:\n",
    "1. extraire automatiquement le vecteur propre associé à la plus grande valeur propre\n",
    "1. projeter les données sur cet axe\n",
    "1. afficher le plot 1D des données suivant:\n",
    "    - x = nouvelle coordonée (unique) du point\n",
    "    - y = étiquette\n",
    "\n",
    "Cet affichage va nous permettre de comprendre ce que nous venons de faire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection sur le premier axe propre\n",
    "# Afficher les points avec leur étiquette\n",
    "\n",
    "#  TODO \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous devez obtenir:\n",
    "\n",
    "<table border=\"0\">\n",
    " <tr>\n",
    "    <td><img src=\"fig/proj_1D.png\" width=300px></td>\n",
    "    <td>L'axe de plus forte variance semble bien intéressant pour distinguer les deux classes de données</td>\n",
    " </tr>\n",
    "</table>\n",
    "\n",
    "Pour mieux comprendre ce qui se passe, je vous propose la figure explicative suivante qui illustre ce que vous avez fait du point de vue géométrique:\n",
    "<img src=\"fig/proj_2D.png\" width=300px>\n",
    "\n",
    "**Note:** cette dernière figure est non-triviale à obtenir, il ne faut pas perdre du temps en TP à chercher comment faire :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réduction de données d-D => 2D\n",
    "\n",
    "Passons maintenant sur USPS pour essayer de reproduire les figures du cours\n",
    "\n",
    "1. extraire automatiquement les 2 vecteurs propres associés aux 2 plus grandes valeurs propres sur les données USPS\n",
    "1. projeter les données sur ces axes\n",
    "    - projeter toutes les données\n",
    "    - projeter seulement les 200 premières images (pour mieux voir)\n",
    "1. afficher avec un code couleur correspondant aux classes\n",
    "\n",
    "Cet affichage va nous permettre de comprendre ce que nous venons de faire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sur les données USPS\n",
    "\n",
    "data = pkl.load(open('data/usps.pkl', 'rb'))\n",
    "Xu = np.array(data['X_train'], dtype=float) # conversion de type pour une meilleure compatibilité\n",
    "Yu = np.array(data['Y_train'], dtype=float)\n",
    "XTu = np.array(data['X_test'], dtype=float) # conversion de type pour une meilleure compatibilité\n",
    "YTu = np.array(data['Y_test'], dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recupération & affichage d'un échantillon\n",
    "index = 0\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(Xu[index].reshape(16,16), cmap=\"gray\")\n",
    "# + affichage du titre + label\n",
    "plt.title(\"label : \"+str(Yu[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calcul Valeur Propre / vecteur propre + tri & projection 2D\n",
    "\n",
    "# pour la cohérence avec la suite:\n",
    "# vp = stockage des vecteurs propres\n",
    "\n",
    "#  TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous devez obtenir:\n",
    "<table border=\"0\">\n",
    " <tr>\n",
    "    <td><img src=\"./fig/proj_USPS_all.png\"></td>\n",
    "    <td><img src=\"./fig/proj_USPS_200.png\"></td>\n",
    " </tr>\n",
    "</table>\n",
    "\n",
    "On a l'impression que les 0 et 1 sont bien séparés des autres classes... Le reste est un peu confus mais on voit que:\n",
    "- les 8 et les 9 se ressemblent\n",
    "- les 6 et les 3 dans une moindre mesure\n",
    "- les 7 et les 4 un peu aussi\n",
    "- les 2 sont en plein milieu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Note : parmi les 1001 biais qui peuvent invalider votre analyse: l'ordre d'affichage des classes !!!**\n",
    "- Les classes sont fortement superposées... L'inversion change-t-elle vos analyse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refaire l'affichage précédent en inversant l'ordre de superposition\n",
    "\n",
    "# TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interprétation des vecteurs propres\n",
    "\n",
    "Chacun de nos 2 axes contient beaucoup d'informations... Mais lesquelles?\n",
    "Ces axes sont en 256 dimensions, il est possible de les tracer comme une image. Le truc est de distinguer les dimensions positives et les dimensions négatives.\n",
    "On ne va pas reconstruire une échelle de couleur propre... Mais on peut a minima afficher l'échelle.\n",
    "\n",
    "Le code est fourni.\n",
    "\n",
    "<img src=\"./fig/usps_vp.png\">\n",
    "   \n",
    "\n",
    "Le premier axe est sensible aux pixels allumés en haut et en bas: sur le premier axe de la figure de la boite précédente, on remarque que les chiffres les plus à droite sont le 0 et le 3... Ca colle.\n",
    "\n",
    "Le second axe est sensible aux pixels à gauche et à droite (en positif) et aux pixels du centre (en négatif). On a bien les 0 en haut et les 1 en bas de ce second axe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choix du nombre de vecteur à afficher\n",
    "nvec = 4\n",
    "\n",
    "plt.figure(facecolor=\"white\")\n",
    "\n",
    "for i in range(nvec):\n",
    "    plt.subplot(1, nvec,i+1)\n",
    "    # il ne reste plus qu'à afficher le vecteur propre (1 ligne !)\n",
    "\n",
    "    # TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vers un espace de représentation débruité [OPT]\n",
    "\n",
    "Que se passe-t-il si on classe les points dans cet espace?\n",
    "En 2d, on voit qu'il n'y a pas assez de dimension... Mais on peut:\n",
    "\n",
    "1. Etudier les valeurs de toutes les valeurs propres (triées) pour voir combien sont importantes\n",
    "    - soit on trie et on affiche les valeurs\n",
    "    - soit on trace un histogramme des valeurs\n",
    "1. Choisir un nombre de vecteurs propres par rapport à l'expérience précédente... On se rend compte que ce n'est pas évident: peu de valeur propre capte toute l'énergie. En tout état de cause, 20 valeurs propres semblent raisonnables\n",
    "1. Projeter les données d'apprentissage et de test\n",
    "1. Etudier le taux de bonne classification dans ce nouvel espace par rapport à l'espace d'origine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etude des valeurs propres\n",
    "\n",
    "plt.figure()\n",
    "#plt.hist(lam, 40)\n",
    "plt.plot(lam)\n",
    "plt.savefig(\"valP.pdf\",bbox_inches='tight', transparent=True,pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# réduction à 20 dimensions\n",
    "ndim = 20\n",
    "Xr = Xu @ V[:,:ndim]\n",
    "XTr = XTu @ V[:,:ndim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apprentissage d'un perceptron multiclasse\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cl = Perceptron()\n",
    "cl.fit(Xr, Yu)\n",
    "\n",
    "ypred_A = cl.predict(Xr)\n",
    "ypred_T = cl.predict(XTr)\n",
    "\n",
    "perf_A = accuracy_score(ypred_A, Yu)\n",
    "perf_T = accuracy_score(ypred_T, YTu)\n",
    "\n",
    "print(\"Perf : \",perf_A, perf_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution des performances en fonction du nombre de vecteurs propres retenus\n",
    "perf = []\n",
    "dims = np.concatenate((np.arange(2,16,2) , np.arange(20,100, 10), np.arange(120,250,20)))\n",
    "\n",
    "\n",
    "for ndim in dims:\n",
    "    Xr = Xu @ V[:,:ndim]\n",
    "    XTr = XTu @ V[:,:ndim]\n",
    "    cl = Perceptron()\n",
    "    cl.fit(Xr, Yu)\n",
    "\n",
    "    ypred_A = cl.predict(Xr)\n",
    "    ypred_T = cl.predict(XTr)\n",
    "\n",
    "    perf_A = accuracy_score(ypred_A, Yu)\n",
    "    perf_T = accuracy_score(ypred_T, YTu)\n",
    "\n",
    "    # print(ndim, \"Perf : \",perf_A, perf_T)\n",
    "    perf.append(perf_T)\n",
    "    if ndim % 10 == 0: print(ndim)\n",
    "plt.figure()\n",
    "plt.plot(dims, perf)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projections non linéaires\n",
    "\n",
    "Les projections linéaires sont utilisées depuis très longtemps... Les projections non-linéaires sont plus récentes mais se développent très rapidement. Une des plus connue est TSNE, qui permet de visualiser les données en conservant les proximités locales (sans tenir compte des distances plus importantes).\n",
    "\n",
    "Attention, dans le cas de TSNE, il s'agit d'une méthode (principalement) transductive: on projete (+affiche) un ensemble mais pas forcément des points supplémentaires ensuite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "# première expériences avec 200 points pour aller vite\n",
    "\n",
    "N = 200\n",
    "Xur = Xu[:N]\n",
    "Yur = Yu[:N]\n",
    "\n",
    "visu = TSNE() # paramètres par défaut\n",
    "x2d = visu.fit_transform(Xur)\n",
    "\n",
    "plt.figure(facecolor=\"white\")\n",
    "for y in np.unique(Yur):\n",
    "    plt.scatter(x2d[Yur==y,0], x2d[Yur==y,1], alpha=0.5)\n",
    "plt.legend(np.arange(10))\n",
    "\n",
    "# plt.savefig(\"fig/tsne-200.png\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultat attendu (à l'initialisation aléatoire près):\n",
    "\n",
    "<img src=\"fig/tsne-200.png\">\n",
    "\n",
    "<span style=\"color:orange\"> L'interprétation du graphique précédent demande de la **prudence**: </span>\n",
    "- il s'agit d'une projection en 2D: **beaucoup d'information ont été perdues**\n",
    "- il s'agit **d'informations locales**: deux points éloignés sont arbitrairement loin. La classe 0 est loin de 1 et de 2 sans qu'on puisse tirer de conclusion sur une relation d'ordre.\n",
    "- l'initialisation est aléatoire: les résultats varient d'une exécution à l'autre (les lointains s'échangent, la formulation est invariante en rotation, etc...). $\\Rightarrow$ faire tourner plusieurs fois avant de tirer des conclusions\n",
    "- la méthode, bien que très optimisée, reste un peu couteuse et ne permet souvent pas de *voir* toutes les données\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "On peut néanmoins tirer quelques conclusions:\n",
    "- les classes 0 et 1 semblent assez faciles\n",
    "- la classe 2 est isolées... Sauf certains points!\n",
    "- la classe 6 est assez proche de 2 mais isolée quand même\n",
    "- les classes 4 et 9 sont franchement mélangées\n",
    "- la classe 8 semble présenter des échantillons durs (éparpillés dans les autres classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Et en dehors de TSNE? [OPT]\n",
    "\n",
    "Les algorithmes de projection en 2D sont nombreux: TSNE est l'arbre qui cache la forêt:\n",
    "https://scikit-learn.org/stable/modules/manifold.html\n",
    "\n",
    "Ca vaut le coup de tester MDS et ISOMAP.\n",
    "\n",
    "UMAP préserve aussi la topologie globale des données (une sorte de compromis entre ACP et TSNE). Une belle démo est disponible ici:\n",
    "https://pair-code.github.io/understanding-umap/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour umap, il faut l'installer:\n",
    "# !pip install umap-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si vous voulez en tester un ou deux !\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage de la visualisation de données pour l'analyse des erreurs\n",
    "\n",
    "1. Construire un classifieur (linéaire) sur USPS\n",
    "1. Afficher les données de test en 2D avec TSNE (sous-ensemble de taille 600)\n",
    "1. Afficher les erreurs et tenter de construire des nouvelles hypothèses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Construction du classifieur\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "mod = LogisticRegression()\n",
    "mod.fit(Xu,Yu)\n",
    "\n",
    "# 2. Prediction + affichage\n",
    "#  TODO \n",
    "\n",
    "# 3. Affichage des points en 2D + erreurs sur les 500 premiers\n",
    "\n",
    "#  TODO \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affichage interactif, évolution dans les algorithmes\n",
    "\n",
    "L'idée suivante est de construire un affichage qui permette d'explorer les données pour comprendre les difficultés spécifiques et les points abbérants.\n",
    "Il faut donc un outils permettant de faire des scatter plot... En introduisant la possibilité de cliquer sur les points ou d'afficher des informations lors du survol des points avec la souris.\n",
    "\n",
    "Plusieurs outils existent, l'un des plus connu est `bokeh`.\n",
    "\n",
    "Les boites suivantes contiennent 2 exemples:\n",
    "1. un simple scatter plot avec la possibilité de zoomer + la présentation des indices de points lors du passage de la souris\n",
    "2. Un exemple plus avancé avec du `callback`: une fonction qui s'active lorsque l'utilisateur déclanche un évènement comme un clic.\n",
    "\n",
    "L'idée était d'afficher directement l'image du point considéré... Mais l'interpréteur web de Visual Studio Code est un peu retourd et il y a des bugs... Tentez de le faire marcher et poser vos questions si vous ne comprennez pas!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.transform import linear_cmap\n",
    "from bokeh.palettes import Spectral8\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "\n",
    "output_notebook()\n",
    "ind = np.arange(len(x2d))\n",
    "data = {'x': x2d[:,0], 'y': x2d[:,1], 'L': Yur, 'index': ind}\n",
    "source = ColumnDataSource(data=data)\n",
    "color_mapper = linear_cmap(field_name='L', palette=Spectral8, low=min(data['L']), high=max(data['L']))\n",
    "\n",
    "p = figure(plot_width=600, plot_height=400)\n",
    "p.circle('x', 'y', source=source, size=10, fill_color=color_mapper,legend_field='L')\n",
    "\n",
    "hover = HoverTool(tooltips=[(\"Classe\", \"@L\"),(\"Index\",\"@index\")])\n",
    "p.add_tools(hover)\n",
    "\n",
    "show(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauvegarde des images pour la version 2 de l'interface\n",
    "# 1. Créer les images + les sauver dasn un repertoire tmp\n",
    "# 2. Les afficher lorsque qu'on clique\n",
    "\n",
    "# attention assez long: on crée + sauvegarde plein d'images\n",
    "\n",
    "import os\n",
    "if not os.path.isdir('tmpfig'):\n",
    "    os.mkdir('tmpfig')\n",
    "for i,x in enumerate(Xur):\n",
    "    plt.imshow(x.reshape(16,16), cmap=\"gray\")\n",
    "    plt.savefig('tmpfig/image_'+str(i)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from bokeh.models import ColumnDataSource, CustomJS\n",
    "from bokeh.layouts import column, row\n",
    "from bokeh.transform import linear_cmap\n",
    "from bokeh.palettes import Spectral8\n",
    "from bokeh.models import HoverTool, TapTool\n",
    "from bokeh.models.widgets import Div\n",
    "\n",
    "\n",
    "output_notebook()\n",
    "ind = np.arange(len(x2d))\n",
    "data = {'x': x2d[:,0], 'y': x2d[:,1], 'L': Yur, 'index': ind}\n",
    "source = ColumnDataSource(data=data)\n",
    "color_mapper = linear_cmap(field_name='L', palette=Spectral8, low=min(data['L']), high=max(data['L']))\n",
    "\n",
    "p = figure(plot_width=600, plot_height=400)\n",
    "p.circle('x', 'y', source=source, size=10, fill_color=color_mapper,legend_field='L')\n",
    "\n",
    "hover = HoverTool(tooltips=[(\"L\", \"@L\")])\n",
    "p.add_tools(hover)\n",
    "\n",
    "# javascript => Afficher les éléments lors du clic (ou un lien vers les éléments)\n",
    "code = \"\"\"\n",
    "    var index = source.data['index'][source.selected.indices[0]];\n",
    "    //div.text = '<img src=\"./tmpfig/image_'+index+'.png\">'; // tentative pour afficher l'image\n",
    "    div.text = '<a href=\"./tmpfig/image_'+index+'.png\"> lien vers image '+index+' <a>'; // '+index+'\n",
    "\"\"\"\n",
    "\n",
    "div = Div(text=\"Cliquez sur un point pour afficher l'indice.\")\n",
    "callback = CustomJS(args={'div': div,'source': source}, code=code)\n",
    "tap = TapTool(callback=callback)\n",
    "p.add_tools(tap)\n",
    "\n",
    "layout = row(p, div)\n",
    "\n",
    "show(layout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploitation de l'interface\n",
    "\n",
    "Avez-vous réussi à identifier des points abbérants?\n",
    "\n",
    "Avez-vous des pistes pour construire un classifieurs plus efficace?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  TODO )\",\" TODO \",\\\n",
    "    txt, flags=re.DOTALL))\n",
    "f2.close()\n",
    "\n",
    "### </CORRECTION> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
