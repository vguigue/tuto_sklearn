{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métriques pièges et chaines de traitement en machine learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage d'outils externes\n",
    "\n",
    "Nous allons continuer à utiliser la méthode `plot_frontiere`... Mais nous allons arrêter de la copier de notebook en notebook. La solution est la suivante:\n",
    "\n",
    "1. Faire un fichier `.py` avec la méthode\n",
    "2. [option, mais plus propre] Mettre cette fonction dans un sous-répertoire (=création d'un module)\n",
    "3. Importer la fonction avec les commandes ci-dessous. \n",
    "\n",
    "**ATTENTION** en plus de l'import, il faut ajouter une petite commande astucieuse qui vérifie si le fichier externe a été modifié et recharge le module lorsque c'est nécessaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from outils.frontiere import plot_frontiere\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Usage des métriques\n",
    "\n",
    "Toujours se rappeler que la métrique n'est pas nécessairement la fonction optimisée:\n",
    "1. Spécificités des données et de la tâche $\\Rightarrow$ définition de la fonction **cout**/**loss** à optimiser\n",
    "2. Présentation des résultats à un expert métier  $\\Rightarrow$ usage d'une **métrique** parlante\n",
    "\n",
    "Pour les approches précision/rappel, toujours garder en mémoire la super-illustration wikipedia:\n",
    "\n",
    "<img src=\"fig/precision_rappel.png\" width = \"400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# données déséquilibrées\n",
    "centers = [[0,0], [1.5,1.5]]\n",
    "clusters_std = [1.5,1.5]\n",
    "X, y = make_blobs(n_samples=100, centers=centers, cluster_std=clusters_std,  n_features=2,   random_state=0) # 100 pts, 2classes, 2dim \n",
    "y    = y * 2 -1 # passage des étiquettes sur [-1 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X[:,0],X[:,1],c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modèle linéaire \n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "mod = LinearSVC()\n",
    "mod.fit(X_train,y_train)\n",
    "\n",
    "plt.figure()\n",
    "plot_frontiere(X_train, y_train, mod)\n",
    "plt.scatter(X_train[:,0], X_train[:,1], c=y_train)\n",
    "plt.title('SVC Linéaire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1 Utiliser les métriques scikit-learn\n",
    "\n",
    "1. Utililser les métriques de base (accuracy) pour calculer les taux de bonnes classification en apprentissage et en test: [lien](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics)\n",
    "\n",
    "1. Calculer et afficher la matrice de confusion en identifiant clairement la notion de *VP, FP, VN, FN* (ie Vrais Positifs, Faux Positifs, Vrais Négatifs, Faux Négatifs).\n",
    "    * Bonus: afficher la matrice avec `imshow` puis ajouter les effectifs sur la figure [il existe aussi une fonction pour le faire directement]\n",
    "\n",
    "    <img src=\"fig/confmat2.png\">\n",
    "\n",
    "1. Calculer la précision et le rappel de chacune des classes\n",
    "    * Commencer par un appel simple à la fonction: combien de score sont-ils calculés? A quoi correspondent-ils?\n",
    "    * Utiliser les fonctions d'affichage\n",
    "\n",
    "    Comment interpréter la figure suivante?\n",
    "\n",
    "    <img src=\"fig/precrapp2.png\">\n",
    "    \n",
    "    * Prenez la place d'un donneur d'ordre: comment exploiter cette courbe au niveau industriel?\n",
    "\n",
    "1. Calculer le score f1\n",
    "\n",
    "**Note: à vous de faire les bons import pour accéder aux fonctions**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploitation et affichage des métriques\n",
    "\n",
    "### <CORRECTION> ###\n",
    "import sklearn.metrics as met\n",
    "\n",
    "print(\"Accuracies (app/test) : \",met.accuracy_score(y_train, mod.predict(X_train)), \\\n",
    "    met.accuracy_score(y_test, mod.predict(X_test)))\n",
    "\n",
    "matconf = met.confusion_matrix(y_train, mod.predict(X_train))\n",
    "#plt.figure()\n",
    "#disp = met.ConfusionMatrixDisplay(confusion_matrix=matconf, display_labels = np.unique(y_train))\n",
    "#disp.plot()\n",
    "#plt.savefig(\"fig/confmat.png\")\n",
    "\n",
    "# précision / rappel\n",
    "print(\"precision/rappel (cl1): \", met.precision_score(y_test, mod.predict(X_test)), \\\n",
    "    met.recall_score(y_test, mod.predict(X_test)))\n",
    "print(\"precision/rappel (cl0): \", met.precision_score(y_test, mod.predict(X_test),pos_label=-1), \\\n",
    "    met.recall_score(y_test, mod.predict(X_test),pos_label=-1))\n",
    "# plt.figure()\n",
    "# disp = met.PrecisionRecallDisplay.from_estimator(mod,X_test,y_test)\n",
    "# disp.plot()\n",
    "# plt.title('Courbe précision rappel (classe 1)')\n",
    "# plt.savefig(\"fig/precrapp.png\")\n",
    "\n",
    "# f1\n",
    "for c in np.unique(y_train):\n",
    "    print(\"f1 \",\"classe:\",c, met.f1_score(y_test, mod.predict(X_test),pos_label=c))\n",
    "\n",
    "### </CORRECTION> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2. Cas déséquilibré, biais et courbe ROC\n",
    "\n",
    "Attention, dans la suite, on se place dans le cas où la classe minoritaire est la classe d'intérêt (fraude, alarme, anomalie, ...) et on va parler de **détection correcte (=VP vrai positif=TP true positive)** et de **fausse alarme (=FP faux positif/False Positive)**.\n",
    "\n",
    "1. La génération des données est fournie\n",
    "1. Ajouter le calcul du score en accuracy (la réponse est assez facile à anticiper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# données déséquilibrées\n",
    "centers = [[0,0], [1.5, 1.5]]\n",
    "clusters_std = [1.5, 0.75]\n",
    "X, y = make_blobs(n_samples=[200,18], centers=centers, cluster_std=clusters_std,  n_features=2,   random_state=0) # 100 pts, 2classes, 2dim \n",
    "y    = y * 2 -1 # passage des étiquettes sur [-1 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X[:,0],X[:,1],c=y)\n",
    "# plt.savefig(\"fig/unbalanced.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modèle linéaire \n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "mod = LinearSVC()\n",
    "mod.fit(X_train,y_train)\n",
    "\n",
    "plt.figure()\n",
    "plot_frontiere(X_train, y_train, mod)\n",
    "plt.scatter(X_train[:,0], X_train[:,1], c=y_train)\n",
    "plt.title('SVC Linéaire')\n",
    "# plt.savefig(\"fig/unbalanced_dec.pdf\")\n",
    "\n",
    "# Ajouter le score en accuracy (en anticipant le résultat):\n",
    "### <CORRECTION> ###\n",
    "print('Performances en accuracy (test): ', met.accuracy_score(y_test, mod.predict(X_test)))\n",
    "### </CORRECTION> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce résultat illustre la difficulté à traiter des données deséquilibrées... Heureusement, il y une première solution simple pour obtenir des résultats:\n",
    "    * on peut décaler la frontière de décision jusqu'à ce qu'un point bascule dans la classe des détectés.\n",
    "    * Puis itérer le processus jusqu'à ce que 100% des points cibles soient détectés\n",
    "    * Cet ensemble de classifieur correspond à autant d'évaluations...\n",
    "        * On retrouve la courbe précision-rappel vue précédemment\n",
    "        * Et on en profite pour introduire la **courbe ROC** [lien](https://fr.wikipedia.org/wiki/Courbe_ROC) qui trace les TP en fonction des FP\n",
    "    $$\\text{Soit } X,Y : \\forall b_i \\in [\\hat y_{max},\\ \\hat y_{min}] \\text{ calculer } score(f(X)+b_i,Y) $$\n",
    "\n",
    "> Courbe ROC = mesure de la capacité à détecter les évènements sans rajouter de bruit en faisant varier la sensibilité\n",
    "\n",
    "<img src=\"fig/roc_anim3.gif\">\n",
    "\n",
    "**Note:** Pour obtenir l'animation facilement, on sauvegarde les images intermédiaires et on passe par un site de création de GIF comme [ezgif](https://ezgif.com/maker/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fabrication d'une courbe ROC\n",
    "\n",
    "# 1. Calcul des scores des points de test:\n",
    "yhat = mod.decision_function(X_test) # ATTENTION, la fonction de score continue dépend du classifieur\n",
    "                                     # seule la fonction de prédiction de classe discrète est générique\n",
    "\n",
    "# 2. Vérification de l'uniformité des scores: tout le monde est dans la même classe...\n",
    "# => 0 détection\n",
    "print(yhat)\n",
    "plt.figure()\n",
    "plt.bar(np.arange(len(yhat)), yhat)\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. On applique l'idée clé: \n",
    "#   a. décaler la frontière (en fonction des valeurs de yhat)\n",
    "#   b. calculer le score du nouveau classifieur\n",
    "\n",
    "TP = [0.] # listes des effectifs True Positive\n",
    "FP = [0.] # listes des effectifs False Positive\n",
    "ACC = [np.where((y_test*yhat>0),1,0).mean()] # controle sur le taux de bonne classification générale\n",
    "\n",
    "# position initiale (0,0): 0 détecté, 0 fausse détection\n",
    "\n",
    "nb_evt    = np.where((y_test>0),1,0).sum()  # pour normaliser les TP entre 0 et 1\n",
    "nb_max_fp = np.where((y_test<=0),1,0).sum() # pour normaliser les FP entre 0 et 1\n",
    "\n",
    "plt.figure(figsize=[15,5])\n",
    "\n",
    "# détermination des valeurs de biais à tester\n",
    "values = np.sort(-yhat[y_test>0]) # toutes les valeurs qui permettent de faire une détection de plus\n",
    "values = np.insert(values, 0, 0) # la valeur extrême pour laquelle tous les points sont détectés\n",
    "values = np.append(values, - yhat.min()) # la valeur extrême pour laquelle tous les points sont détectés\n",
    "\n",
    "# boucle sur les biais\n",
    "for i,b in enumerate(values): # evolution du biais b\n",
    "    # 1. Décaler yhat (dans une nouvelle variable)\n",
    "    # 2. calculer TP, FP et accuracy\n",
    "    # 3. faire les affichages\n",
    "    #    - c'est un peu long... Pas besoin de peaufiner (réglage des axes...)\n",
    "\n",
    "    ### <CORRECTION> ###\n",
    "\n",
    "    y_tmp = yhat + b + 1e-6 \n",
    "    # print(y_tmp)\n",
    "    tp    = np.where((y_tmp>0) & (y_test>0),1,0).sum()  /nb_evt # taux bonne détection\n",
    "    fp    = np.where((y_tmp>0) & (y_test<=0),1,0).sum() /nb_max_fp # fausse détection\n",
    "    acc   = np.where((y_test*y_tmp>0),1,0).mean()\n",
    "\n",
    "    TP.append(tp)\n",
    "    FP.append(fp)\n",
    "    ACC.append(acc)\n",
    "    #print(FP,TP)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.subplot(1,3,1)\n",
    "    plot_frontiere(X_test, y_test, mod, biais=b)\n",
    "    plt.scatter(X_test[:,0], X_test[:,1], c=y_test)\n",
    "    plt.title('SVC Linéaire b='+str(b))\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.plot(FP,TP)   \n",
    "    plt.scatter(FP[-1],TP[-1])\n",
    "    plt.axis([0.,1.,0.,1.05])\n",
    "    plt.grid()\n",
    "    plt.xlabel('FP')\n",
    "    plt.ylabel('TP')\n",
    "    plt.title('ROC')\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.plot(ACC)\n",
    "    plt.scatter(i+1,ACC[-1])\n",
    "    plt.grid()\n",
    "    plt.axis([0,len(values),0,1])\n",
    "    plt.title('Tx bonne classification')\n",
    "\n",
    "    # plt.savefig('fig/anim/roc_'+str(i)+'.png')\n",
    "\n",
    "    ### </CORRECTION> ###\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### <CORRECTION> ###\n",
    "from turtle import color\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.patches import PathPatch\n",
    "\n",
    "fpr, tpr, thresholds = met.roc_curve(y_test, yhat, pos_label=1)\n",
    "sc = met.auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(FP,TP,lw=3,c='b')   \n",
    "FP.append(1)\n",
    "TP.append(0)\n",
    "path = Path(np.array([FP,TP]).transpose())\n",
    "patch = PathPatch(path,color='b', alpha=0.5)\n",
    "plt.gca().add_patch(patch)\n",
    "\n",
    "plt.axis([0.,1.,0.,1.05])\n",
    "plt.grid()\n",
    "plt.xlabel('FP')\n",
    "plt.ylabel('TP')\n",
    "plt.title('ROC => AUC = {:4.2f}'.format(sc))\n",
    "#plt.savefig('fig/auc.png')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "disp = met.PrecisionRecallDisplay.from_estimator(mod,X_test,y_test)\n",
    "disp.plot()\n",
    "plt.title('Courbe précision rappel (classe 1)')\n",
    "# plt.savefig(\"fig/precrappU.png\")\n",
    "\n",
    "### </CORRECTION> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.3. Agrégation d'indicateurs\n",
    "\n",
    "Les data-scientistes ont horreur de manipuler différents indicateurs: pour fusionner **précision** et **rappel**, on a calculé le **f1-score**. Evidemment, la courbe ROC pose problème: il s'agit d'une liste de score difficile à expliquer aux experts métier.\n",
    "\n",
    "Pour la courbe ROC, l'idée est de calculer l'aire sous la courbe (**AUC: Area Under the Curve**): \n",
    "- plus la courbe passe *en haut à gauche*, plus l'aire couverte est grande (i.e. on a bien détecter les évènements sans ajouter de bruit) $\\Rightarrow$ l'aire tend vers 1\n",
    "- plus la courbe passe *sur la diagonale*, plus l'aire couverte est petite (i.e. à chaque mouvement, on ajoute autant de détection que de bruit) $\\Rightarrow$ l'aire tend vers 0.5\n",
    "\n",
    "<img src=\"fig/auc.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer l'indicateur AUC correspondant au problème précédent:\n",
    "\n",
    "### <CORRECTION> ###\n",
    "fpr, tpr, thresholds = met.roc_curve(y_test, yhat, pos_label=1)\n",
    "sc = met.auc(fpr, tpr)\n",
    "print(\"auc: \", sc)\n",
    "\n",
    "### </CORRECTION> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Fonctions scikit-learn avancées : validation croisée\n",
    "\n",
    "On a déjà vu ci-dessus les fonctions de séparation d'un jeu de données en apprentissage et test: cette fonction marche très bien dans la plupart des cas.\n",
    "\n",
    "`X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)`\n",
    "\n",
    "\n",
    "Cette section explique comment passer à la validation croisée dans le cas où les données ne sont pas disponibles en quantité suffisante.\n",
    "\n",
    "\n",
    "Nous avons testé différentes fonctions permettant le calcul des métriques usuelles en machine learning. Mais nous n'avons pas encore abordé le problème de la validation croisée. 2 principales solutins sont proposées dans scikit-learn:\n",
    "1. Boucle `for`:\n",
    "    * Séparation des données \n",
    "    * Apprentissage\n",
    "    * Evaluation sur les données de test\n",
    "2. Lancement d'une fonction effectuant toutes les opérations (et retournant les scores en test)\n",
    "    * Rapide, pratique\n",
    "    * Facilement parallélisable (cf `njob`)\n",
    "    * Non adapté quand on veut avoir la main sur les données intermédiaires.\n",
    "\n",
    "**Note:** afin d'être robuste au cas déséquilibré, il est plus efficace de prendre les options `stratified` qui garantissent la même répartition des classes en apprentissage et en test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.1. Exemples de fonctionnement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération des données\n",
    "centers = [[0,0], [1.5,1.5]]\n",
    "clusters_std = [1.5,1.5]\n",
    "X, y = make_blobs(n_samples=100, centers=centers, cluster_std=clusters_std,  n_features=2,   random_state=0) # 100 pts, 2classes, 2dim \n",
    "y    = y * 2 -1 # passage des étiquettes sur [-1 1]\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X[:,0], X[:,1], c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "n_fold = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_fold) # Objet validation croisée stratifiée\n",
    "\n",
    "allp = []\n",
    "for train, test in skf.split(X, y): # récupération des indexs\n",
    "    mod = SVC()\n",
    "    mod.fit(X[train],y[train])\n",
    "    yhat = mod.predict(X[test])\n",
    "    perf = accuracy_score(yhat,y[test])\n",
    "    allp.append(perf)\n",
    "    print('perf : ', perf)\n",
    "\n",
    "print('Estimation moyenne : ',np.mean(allp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 2\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# définition du modèle\n",
    "mod = SVC()\n",
    "n_fold = 5\n",
    "\n",
    "scores = cross_val_score(mod, X, y, cv=n_fold, scoring='accuracy') # tout est caché dedans :)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.2. Votre tour\n",
    "\n",
    "Sur ces données jouets, calculer la performance en validation croisée d'un modèle bayesien naïf, d'un SVM linéaire et d'une forêt aléatoire. Sélectionner le modèle le plus performant.\n",
    "\n",
    "**Note:** on se limite aux modèles avec les paramètres par défaut. [la solution est donc très courte]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Sélection de modèles \n",
    "\n",
    "L'idée est à la fois de trouver la meilleure classe de modèle (déjà fait ci-dessus)... Mais aussi les paramères optimaux des modèles. Le terme **sélection de modèle** regroupe les deux problématiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.1. Processus classique\n",
    "\n",
    "1. Liste des modèles\n",
    "2. Evaluation\n",
    "\n",
    "**Note:** on peut utiliser la validation croisée si on manque de données ou une procédure plus simple si la masse est suffisante.\n",
    "\n",
    "**Note 2:** globalement, le processus est très proche de la section précédente...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# données déséquilibrées\n",
    "centers = [[0,0], [1.5,1.5]]\n",
    "clusters_std = [1.5,1.5]\n",
    "X, y = make_blobs(n_samples=100, centers=centers, cluster_std=clusters_std,  n_features=2,   random_state=0) # 100 pts, 2classes, 2dim \n",
    "y    = y * 2 -1 # passage des étiquettes sur [-1 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X[:,0],X[:,1],c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "param = [0.01, 0.05, 0.1, 0.5, 1, 5 ]\n",
    "allp = []\n",
    "plt.figure(figsize=[4*len(param),4])\n",
    "\n",
    "for i,gam in enumerate(param):\n",
    "    mod = SVC(gamma=gam)\n",
    "    mod.fit(X_train,y_train)\n",
    "    yhat = mod.predict(X_test)\n",
    "    perf = accuracy_score(yhat,y_test)\n",
    "    allp.append(perf)\n",
    "\n",
    "    # affichage \n",
    "    plt.subplot(1,len(param),i+1)\n",
    "    plot_frontiere(X,y,mod)\n",
    "    plt.scatter(X_train[:,0],X_train[:,1],c=y_train)\n",
    "    plt.title('SVC $\\gamma=${}, perf={:.2f}'.format(gam,perf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.2. Grid Search\n",
    "\n",
    "Ce que l'on a fait ci-dessus à la main correspond à ce que les data-scientists nomment *grid-search*: recherche de valeur(s) optimale(s) sur un axe, ou une grille lorsqu'on est plusieurs paramètres.\n",
    "\n",
    "Le code ci-dessous envisage deux cas de figure:\n",
    "\n",
    "1. Reproduction de l'exemple précédent (recherche sur un axe) avec une fonction plus efficace\n",
    "    * paramètre $\\gamma$ du noyau gaussien dans un SVM\n",
    "1. Recherche sur deux axes (=grille) =>  TODO\n",
    "    * paramètre $\\gamma$ + paramètre de régularisation\n",
    "\n",
    "\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#\n",
    "\n",
    "**Note:** la documentation est importante. Il est possible de définir partiellement des grilles lorsque les combinaisons de certains paramètres n'ont pas de sens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cas 1: recherche sur un axe\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# définition du modèle générique\n",
    "mod = SVC()\n",
    "# dictionnaire: key = nom du paramètre dans le classifieur\n",
    "parameters = {'gamma' : [0.01, 0.05, 0.1, 0.5, 1, 5 ]}\n",
    "meta_mod = GridSearchCV(estimator=mod, param_grid=parameters, cv=3)\n",
    "meta_mod.fit(X_train,y_train) # la validation croisée va être effectuée sur les données de train\n",
    "print(meta_mod.cv_results_.keys()) # pour voir ce qui est disponible\n",
    "\n",
    "# exploration\n",
    "print(meta_mod.cv_results_['mean_test_score'])\n",
    "print(meta_mod.cv_results_['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.3. Votre tour\n",
    "\n",
    "1. Ajouter une recherche de paramètre de régularisation sur le problème précédent. vous devez obtenir une figure comme celle ci-dessous:\n",
    "\n",
    "<img src ='fig/gridsearch.png'>\n",
    "\n",
    "2. [@home] Trouver les paramètres optimaux d'une forêt aléatoire (nombre d'arbres et profondeur) pour ce problème"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cas 2: recherche sur 2 axes\n",
    "# Jouer avec les paramètres de régularisation en plus du réglage de gamma\n",
    "\n",
    "### <CORRECTION> ###\n",
    "mod = SVC()\n",
    "# dictionnaire: key = nom du paramètre dans le classifieur\n",
    "parameters = {'C' : [0.001,0.1, 1, 10, 100, 1000],'gamma' : [0.001,0.01, 0.05, 0.1, 0.5, 1, 5 ]}\n",
    "meta_mod = GridSearchCV(estimator=mod, param_grid=parameters, cv=3)\n",
    "\n",
    "meta_mod.fit(X_train,y_train) # la validation croisée va être effectuée sur les données de train\n",
    "print(meta_mod.cv_results_.keys()) # pour voir ce qui est disponible\n",
    "\n",
    "# exploration\n",
    "print(meta_mod.cv_results_['mean_test_score'])\n",
    "print(meta_mod.cv_results_['params'])\n",
    "### </CORRECTION> ###\n",
    "\n",
    "# Identifier les paramètres optimaux + tracé des performances\n",
    "from matplotlib import cm\n",
    "\n",
    "acc = np.array(meta_mod.cv_results_['mean_test_score'])\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.imshow(acc.reshape(len(parameters['C']), len(parameters['gamma'])),cmap=cm.coolwarm)\n",
    "plt.ylabel('C')\n",
    "plt.yticks(np.arange(len(parameters['C'])), parameters['C'])\n",
    "plt.xlabel('gamma')\n",
    "plt.xticks(np.arange(len(parameters['gamma'])), parameters['gamma'])\n",
    "plt.colorbar()\n",
    "\n",
    "# plt.savefig('fig/gridsearch.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification de la cohérence du graphique ci-dessus\n",
    "print([(p,a) for p,a in zip(meta_mod.cv_results_['params'],meta_mod.cv_results_['mean_test_score'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "### <CORRECTION> ###\n",
    "import re\n",
    "# transformation de cet énoncé en version étudiante\n",
    "\n",
    "fname = \"notebook-metrique-corr.ipynb\" # ce fichier\n",
    "fout  = fname.replace(\"-corr\",\"\")\n",
    "\n",
    "# print(\"Fichier de sortie: \", fout )\n",
    "\n",
    "f = open(fname, \"r\")\n",
    "txt = f.read()\n",
    "\n",
    "f.close()\n",
    "\n",
    "\n",
    "f2 = open(fout, \"w\")\n",
    "f2.write(re.sub(\"<CORRECTION>.*?(</CORRECTION>)\",\" TODO \",\\\n",
    "    txt, flags=re.DOTALL))\n",
    "f2.close()\n",
    "\n",
    "### </CORRECTION> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "902a52bcf4503a473db011f1937bdfe17613b08622219712e0110e48c4958c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
