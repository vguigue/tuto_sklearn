{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sélection de caractéristiques\n",
    "\n",
    "Comme nous l'avons vu en cours, les approches de machine-learning ne sont pas réellement capables de sélectionner les bonnes caractéristiques: il est donc essentiel de sélectionner les informations utiles et d'éliminer (au moins une part) de l'information inutile.\n",
    "\n",
    "Ce notebook vise à reproduire l'essentiel des expéricences vues dans les transparents de cours: ce sont les exemples que nous trouvons les plus parlant pour mettre en évidence l'importance de cette tâche critique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from outils.frontiere import *\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# données + dimensions inutiles\n",
    "centers = [[-2.0, -2.0], [2.0, 2.0]]\n",
    "clusters_std = [1.5, 1.5]\n",
    "X, y = make_blobs(n_samples=100, centers=centers, cluster_std=clusters_std,  n_features=2,   random_state=0) # 100 pts, 2classes, 2dim \n",
    "\n",
    "# ajout de bruit\n",
    "ndim_noise = 20\n",
    "Noise = np.random.randn(len(X), ndim_noise)*clusters_std[0]\n",
    "Xn = np.concatenate((X,Noise), axis=1)\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xn, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation des données complètes\n",
    "\n",
    "ind = np.argsort(y_train)\n",
    "plt.figure(facecolor='white')\n",
    "\n",
    "plt.imshow(X_train[ind])\n",
    "#plt.savefig(\"fig/Xbruit.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Curse of dimensionality / fléau de la dimensionalité\n",
    "\n",
    "1. Vérifier la dimension des données générées ci-dessus\n",
    "2. Vérifier que vous pouvez afficher ce problème jouet en utilisant les deux premières dimension de `X_train`\n",
    "3. Reproduction de l'expérience sur le fléau de la dimensionalité\n",
    "\n",
    "<img src = \"fig/curse.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension de X\n",
    "\n",
    "# Scatter plot de X (deux première dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproduction de l'expérience sur le fléau de la dimensionalité\n",
    "mod = svm.SVC(gamma = 0.1) # proposition de classifieur qui doit mettre en évidence le phénomène de sur-apprentissage\n",
    "perf_train = []\n",
    "perf_test  = []\n",
    "\n",
    "# on commence par les données de base et on ajoute progressivement du bruit\n",
    "for ndim in range(2,X_train.shape[1],4) : # Ajout des dimensions de bruit 4 par 4\n",
    "    # 1.extraction des données temporaire\n",
    "    # 2. apprentissage du modèle\n",
    "    # 3. Evaluation et stockage (poour le tracé de la courbe)\n",
    "\n",
    "    # <CORRECTION>\n",
    "    xtmp = X_train[:,:ndim]\n",
    "    mod.fit(xtmp,y_train)\n",
    "    yhat_a = mod.predict(X_train[:,:ndim])\n",
    "    yhat_t = mod.predict(X_test[:,:ndim])\n",
    "    perf_train.append(accuracy_score(y_train,yhat_a))\n",
    "    perf_test.append(accuracy_score(y_test,yhat_t))\n",
    "    # </CORRECTION>\n",
    "\n",
    "# avec tous les résultats stockés dans:\n",
    "# perf_train\n",
    "# perf_test\n",
    "plt.figure(facecolor='white')\n",
    "plt.plot(perf_train)\n",
    "plt.plot(perf_test)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Itération\")\n",
    "plt.xlabel(\"Taux de bonne classif\")\n",
    "plt.legend(['Train', 'Test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Réduction / sélection de dimensions\n",
    "\n",
    "Les stratégies d'analyse des poids du classifieur linéaire et de *feature importance* sur les forêts aléatoires sont utiles... Mais elles ont été vues dans le dernier TP et ne sont pas reprise ici.\n",
    "\n",
    "\n",
    "### B.0. Stratégies naïves, parfois très efficace\n",
    "\n",
    "... Mais pas tout le temps\n",
    "\n",
    "* Expérience naïve de corrélation entre les variables et $y$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul de correlation entre les variables et y\n",
    "\n",
    "corr = np.abs(X_train.T @ y_train)\n",
    "plt.figure()\n",
    "plt.bar(np.arange(len(corr)), corr)\n",
    "\n",
    "# ... Sur un exemple jouet, ça marche vraiment très bien ...\n",
    "# A tester sur des exemples réels, on ne sait jamais, le critère est intéressant !\n",
    "\n",
    "#plt.savefig(\"fig/corr_var.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## B.1. Stratégies implémentées dans scikit-learn\n",
    "\n",
    "Nous allons voir quelques stratégies de réduction de la dimensionnalité:\n",
    "\n",
    "* Elimination successive des dimensions les moins intéressantes (ou ajout des dimensions intéressante)\n",
    "    * Avant toute chose: il faut un critère de sélection (ici, le taux de bonne classification d'un SVC)\n",
    "    * doc: [lien](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html#sklearn.feature_selection.SequentialFeatureSelector)\n",
    "    * Stratégie potentiellement **très couteuse**: il faut bien regarder les paramètres\n",
    "        * Que penser de la différence entre *forward* et *backward*\n",
    "\n",
    "* Point de vue syntaxique:\n",
    "    * ```fit``` faire tous les calculs\n",
    "    * ```transform``` appliquer la sélection de dimension sur X & Xtest (éliminer effectivement les dimensions non retenue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "estimator = svm.SVC(kernel=\"linear\") # je choisis d'utiliser le score en classif d'un SVM lineaire\n",
    "selector = SequentialFeatureSelector(estimator, n_features_to_select=2) # le nombre de dimension à garder est spécifié... \n",
    "                                                                        # ... Pas très réaliste: en général, il faut tester!\n",
    "selector = selector.fit(X_train, y_train) # calcul des dimensions à conserver\n",
    "\n",
    "print(selector.get_support())\n",
    "\n",
    "# il eset ensuite possible de filtrer les données:\n",
    "Xnew = selector.transform(X_train) # application du filtre\n",
    "print(\"Ancienne dimensions : \",X_train.shape)\n",
    "print(\"Nouvelles dimensions : \",Xnew.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impact en temps de calcul des options:\n",
    "import time\n",
    "\n",
    "# forward\n",
    "t = time.time()\n",
    "estimator = svm.SVC(kernel=\"linear\")\n",
    "selector = SequentialFeatureSelector(estimator, n_features_to_select=2)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "print(selector.get_support())\n",
    "print(\"durée: {}\".format(time.time()-t))\n",
    "\n",
    "# backward\n",
    "# Ajouter la bonne option et lancer le chronomètre. \n",
    "# bien comprendre l'algorithme qui tourne derrière\n",
    "### <CORRECTION> ###\n",
    "t = time.time()\n",
    "estimator = svm.SVC(kernel=\"linear\")\n",
    "selector = SequentialFeatureSelector(estimator, n_features_to_select=2, direction=\"backward\")\n",
    "selector = selector.fit(X_train, y_train)\n",
    "print(selector.get_support())\n",
    "print(\"durée: {}\".format(time.time()-t))\n",
    "### </CORRECTION> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.2. ACP/PCA : Analyse en composantes principales\n",
    "\n",
    "Trouver les combinaisons de variables qui permettent *d'expliquer les données*\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "\n",
    "* Ce critère, très efficace et très utilisé, n'est pas lié aux étiquettes $y$!\n",
    "* dans ce critère, on peut analyser les valeurs propres pour choisir combien d'axes conserver\n",
    "\n",
    "<img src=\"fig/valp.png\">\n",
    "\n",
    "* D'après la figure, une valeur propre (ou deux) sont suffisantes pour bien représenter les données...\n",
    "    * Projeter les données dans cet espace\n",
    "    * Apprendre un classifieur et comparer les performances par rapport à l'espace de représentation d'origine\n",
    "\n",
    "<img src=\"fig/pca.png\">\n",
    "\n",
    "**Note:** Les performances sur 1 seule dimension sont quasi-optimales! <BR>\n",
    "**Note 2:** Quand on prend tous les axes, on retrouve le piètre niveau de performance original (logique, l'information est la même) <BR>\n",
    "**Notes 3:** Comment expliquer que les meilleures perfromances soient obtenues avec ```n_comp=8```?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# application de la PCA\n",
    "\n",
    "pca = PCA() # on peut préciser le nombre de valeurs propres à\n",
    "            # conserver /calculer: n_components=10\n",
    "pca.fit(X_train)  # calcul des valeurs propres, vecteurs propres\n",
    "\n",
    "# Analyse des valeurs propres:\n",
    "plt.figure(facecolor='white', figsize=[8,4])\n",
    "plt.subplot(1,2,1)\n",
    "plt.bar(np.arange(X_train.shape[1]), pca.singular_values_)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.grid()\n",
    "#plt.savefig('fig/valp.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.2.1 Evolution des performances en fonction de la dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projection des données dans cet espace à un ou deux axes:\n",
    "# + apprentissage de modele\n",
    "# + evaluation des performances\n",
    "\n",
    "Xnew = pca.transform(X_train) # projection sur tous les axes\n",
    "XnewT = pca.transform(X_test) # projection sur tous les axes\n",
    "\n",
    "# boucle for:\n",
    "#   Xnew = proj sur 1, 2, 3, ... d vecteurs propres\n",
    "#   Apprentissage modèle\n",
    "#   Evaluation des performances\n",
    "# => Conclusion: sur combien de dimension faut-il projeter?\n",
    "\n",
    "### <CORRECTION> ###\n",
    "\n",
    "mod = svm.SVC(gamma = 0.1)\n",
    "perf_train = []\n",
    "perf_test  = []\n",
    "\n",
    "for ndim in range(1,Xnew.shape[1]):\n",
    "    Xd = Xnew[:,:ndim]\n",
    "    Xd_T = XnewT[:,:ndim]\n",
    "    mod.fit(Xd,y_train)\n",
    "    perf_train.append(accuracy_score(mod.predict(Xd), y_train))\n",
    "    perf_test.append(accuracy_score(mod.predict(Xd_T), y_test))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(perf_train)\n",
    "plt.plot(perf_test)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Itération\")\n",
    "plt.xlabel(\"Taux de bonne classif\")\n",
    "plt.legend(['Train', 'Test'])\n",
    "#plt.savefig('fig/pca.png')\n",
    "    \n",
    "### </CORRECTION> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.2.2 Réduction en 2D = possibilité de visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage de nuage de point projeté en 1D et 2D\n",
    "\n",
    "# projeter les données en 1 ou 2 dimensions => capacité de visualisation\n",
    "\n",
    "### <CORRECTION> ###\n",
    "plt.figure(figsize=[15,5])\n",
    "plt.subplot(1,3,1)\n",
    "plt.scatter(X_train[:,0], X_train[:,1], c=y_train)\n",
    "scal = 20\n",
    "plt.plot([0, pca.components_[0][0]*scal/5],[0, pca.components_[0][1]*scal/5],lw=2)\n",
    "plt.plot([0, pca.components_[1][0]*scal],[0, pca.components_[1][1]*scal],lw=2)\n",
    "\n",
    "plt.title('2D (originale, avant dimensions ajoutées)')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.scatter(Xnew[:,0], [0]*len(X_train), c=y_train)\n",
    "plt.title('1D')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.scatter(Xnew[:,0], Xnew[:,1], c=y_train)\n",
    "plt.title('2D')\n",
    "\n",
    "# plt.savefig(\"fig/pca1d2d.png\")\n",
    "### </CORRECTION> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.2.3 Application sur les données en grande dimension [séance dédiée un peu plus tard]\n",
    "\n",
    "Peut-on utiliser la PCA sur les données USPS avec lesquelles nous avons joué il y a quelques semaines??\n",
    "\n",
    "OUI! Evidemment.\n",
    "\n",
    "* Idée 1: on va visualiser les données USPS en 2 dimensions!\n",
    "* Idée 2: on va voir s'il est possible de classer les données USPS dans cet espace réduit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "import pickle as pkl\n",
    "data = pkl.load(open(\"data/usps.pkl\",'rb')) \n",
    "# data est un dictionnaire contenant les champs explicites X_train, X_test, Y_train, Y_test\n",
    "X_train = np.array(data[\"X_train\"],dtype=float) # changement de type pour éviter les problèmes d'affichage\n",
    "X_test = np.array(data[\"X_test\"],dtype=float)\n",
    "Y_train = data[\"Y_train\"]\n",
    "Y_test = data[\"Y_test\"]\n",
    "\n",
    "# pour rappel sur la structuration des données: affichage de l'image 18 avec reshape\n",
    "plt.figure()\n",
    "plt.imshow(X_train[18].reshape(16,16),cmap=\"gray\")\n",
    "plt.title(\"Image de : {}\".format(Y_train[18]))\n",
    "\n",
    "# Faire la projection\n",
    "\n",
    "# Affichage de la base projetée sur les deux premiers axes\n",
    "\n",
    "# Afficher également les axes de projection eux-mêmes\n",
    "\n",
    "# Calculer la performance en fonction du nombre d'axes utilisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### <CORRECTION> ###\n",
    "\n",
    "plt.figure(figsize=[12,4])\n",
    "plt.subplot(1,4,1)\n",
    "plt.hist(X_train[:,0])\n",
    "plt.title('Pixel 0')\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.hist(X_train[:,18])\n",
    "plt.title('Pixel 18')\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.hist(X_train[:,37])\n",
    "plt.title('Pixel 37')\n",
    "\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.hist(X_train[:,128])\n",
    "plt.title('Pixel 128')\n",
    "\n",
    "# plt.savefig('fig/distrib_pix.pdf')\n",
    "\n",
    "### </CORRECTION> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.3. Régularisation\n",
    "\n",
    "La promesse : sélectionner les bonnes dimensions au cours de l'apprentissage. Nous avons vu les mécanismes dans la séance sur le gradient.\n",
    "\n",
    "* Pénalisation extrême des poids => Aucune dimension retenue (= simplicité extrême)... Mais performances très faible.\n",
    "* Pénalisation faible: retour à la situation initiale (bonne perf mais risque de sur-apprentissage)\n",
    "* **Question:** quid des situations intermédiaires? Quel compromis entre parcimonie et performances?\n",
    "\n",
    "Nous allons envisager plusieurs formulations, faire varier la régularisation et étudier à la fois la performance et la parcimonie. Comme indicateur de parcimonie, nous étudierons le pourcentage de $w$ non nul:\n",
    "\n",
    "$$Parcimonie = \\frac{\\sum_j I_{w_j \\ne 0}}{d}$$\n",
    "\n",
    "### B.3.1. Régularisation L2\n",
    "\n",
    "Nous avons déjà croisé la régularisation L2 avec les SVM. Essayons de pousser un peu plus loin l'analyse de ce type d'approches:\n",
    "\n",
    "$$\\text{Formulation Ridge: }\\qquad \\mathcal L = \\sum_{i=1}^n \\left( \\sum_{j=1}^d w_j x_{ij} - y_i\\right)^2 + \\textcolor{red}{C} \\|w\\|^2$$\n",
    "\n",
    "Après la phase de génération de données, nous allons faire varier $C$ et étudier les performances par rapport au nombre de variables retenues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (re)génération des données bruitées\n",
    "\n",
    "# données + dimensions inutiles\n",
    "centers = [[-2.0, -2.0], [2.0, 2.0]]\n",
    "clusters_std = [1.5, 1.5]\n",
    "X, y = make_blobs(n_samples=100, centers=centers, cluster_std=clusters_std,  n_features=2,   random_state=0) # 100 pts, 2classes, 2dim \n",
    "\n",
    "# ajout de bruit\n",
    "ndim_noise = 20\n",
    "Noise = np.random.randn(len(X), ndim_noise)*clusters_std[0]\n",
    "Xn = np.concatenate((X,Noise), axis=1)\n",
    "\n",
    "# split (données classique + données bruitées)\n",
    "Xn_train, Xn_test, yn_train, yn_test = train_test_split(Xn, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "# différentes valeurs de C sur les données d'origine\n",
    "\n",
    "all_a = 10**(np.linspace(10,-10,11))\n",
    "p_a = [] # perf en apprentissage\n",
    "p_t = [] # perf en test\n",
    "wc = []  # cardinal des coefficients non nul\n",
    "\n",
    "for a in all_a: # boucle de test de régularisation.\n",
    "    mod = RidgeClassifier(alpha=a)\n",
    "    mod.fit(Xn_train,yn_train)\n",
    "    # Compléter l'évaluation et le comptage des coefficients non nuls\n",
    "    ###  <CORRECTION> ###\n",
    "    yhata = mod.predict(Xn_train)\n",
    "    yhatt = mod.predict(Xn_test)\n",
    "    p_a.append(accuracy_score(yhata, yn_train))\n",
    "    p_t.append(accuracy_score(yhatt, yn_test))\n",
    "    # print(mod.coef_)\n",
    "    wc.append(np.where(np.abs(mod.coef_[0])>1e-5, 1, 0).mean())\n",
    "    ###  </CORRECTION> ###\n",
    "    \n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(p_a)\n",
    "plt.plot(p_t)\n",
    "plt.plot(wc)\n",
    "plt.grid()\n",
    "plt.xlabel('Régularisation (décroissante)')\n",
    "plt.ylabel('Perf / Nombre dim')\n",
    "plt.legend(['P train', 'P test', '#w'])\n",
    "plt.gcf().set_facecolor('white')\n",
    "\n",
    "# plt.savefig('fig/reg_L2.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.3.2. Régularisation L1\n",
    "\n",
    "Introduction d'une régularisation parcimonieuse\n",
    "\n",
    "$$\\text{Formulation LASSO: }\\qquad \\mathcal L = \\sum_{i=1}^n \\left( \\sum_{j=1}^d w_j x_{ij} - y_i\\right)^2 + \\textcolor{red}{C} \\sum_{j=1}^d |w_j|$$\n",
    "\n",
    "Après la phase de génération de données, nous allons faire varier $C$ et étudier performances vs sparsité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import lasso_path\n",
    "\n",
    "# différentes valeurs de C sur les données d'origine (fait automatiquement ici)\n",
    "alphas,  coef_ ,active = lasso_path(Xn_train,yn_train) # fit automatique à l'intérieur\n",
    "# note: le modèle LASSO marche comme les autres modèles\n",
    "# pour gagner du temps, j'ai juste calculer tous les modèles d'un coup :)\n",
    "\n",
    "p_a = []\n",
    "p_t = []\n",
    "wc = []\n",
    "\n",
    "for i in range(coef_.shape[1]):\n",
    "    \n",
    "    yhata = np.where(Xn_train.dot(coef_[:,i]) > 0.5, 1, 0)  # ATTENTION, c'est un modèle de régression: \n",
    "                                                            # il faut fabriquer les étiquettes à la main\n",
    "    yhatt = np.where(Xn_test.dot(coef_[:,i]) > 0.5, 1, 0)\n",
    "    p_a.append(accuracy_score(yhata, yn_train))\n",
    "    p_t.append(accuracy_score(yhatt, yn_test))\n",
    "    wc.append(np.where(np.abs(coef_[:,i])>1e-5, 1, 0).mean())\n",
    "    \n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(p_a)\n",
    "plt.plot(p_t)\n",
    "plt.plot(wc)\n",
    "plt.grid()\n",
    "plt.xlabel('Régularisation (décroissante)')\n",
    "plt.ylabel('Perf / Nombre dim')\n",
    "plt.legend(['P train', 'P test', '#w'])\n",
    "plt.gcf().set_facecolor('white')\n",
    "\n",
    "# plt.savefig('fig/reg_L1.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.3.3. Régularisation Elastic Net\n",
    "\n",
    "Combinaison de deux régularisations L2 et L1. L'idée est de jouer principalement sur la L2 et de mettre un peu de L1 pour la sparsité.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# différentes valeurs de C sur les données d'origine\n",
    "\n",
    "all_a = (np.linspace(2.5,0.1,20))\n",
    "p_a = [] # perf en apprentissage\n",
    "p_t = [] # perf en test\n",
    "wc = []  # cardinal des coefficients non nul\n",
    "\n",
    "for a in all_a:\n",
    "    mod = ElasticNet(alpha=a, l1_ratio=0.5)\n",
    "    mod.fit(Xn_train,yn_train)\n",
    "    # Compléter l'évaluation et le comptage des coefficients non nuls\n",
    "    # ATTENTION: par défaut, il s'agit d'un modèle de régression: \n",
    "    # il faut remettre les classes en face des classes pour utiliser les métriques\n",
    "    ###  <CORRECTION> ###\n",
    "    yhata = np.where(mod.predict(Xn_train)  > 0.5, 1, 0)\n",
    "    yhatt = np.where(mod.predict(Xn_test) > 0.5, 1, 0)\n",
    "    p_a.append(accuracy_score(yhata, yn_train))\n",
    "    p_t.append(accuracy_score(yhatt, yn_test))\n",
    "    # print(mod.coef_)\n",
    "    wc.append(np.where(np.abs(mod.coef_)>1e-7, 1, 0).mean())\n",
    "    ###  </CORRECTION> ###\n",
    "    \n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(p_a)\n",
    "plt.plot(p_t)\n",
    "plt.plot(wc, '+-')\n",
    "plt.grid()\n",
    "plt.xlabel('Régularisation (décroissante)')\n",
    "plt.ylabel('Perf / Nombre dim')\n",
    "plt.legend(['P train', 'P test', '#w'])\n",
    "plt.gcf().set_facecolor('white')\n",
    "\n",
    "\n",
    "#plt.savefig('fig/reg_L1L2.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### <CORRECTION> ###\n",
    "import re\n",
    "# transformation de cet énoncé en version étudiante\n",
    "\n",
    "fname = \"3-notebook-selfeat-corr.ipynb\" # ce fichier\n",
    "fout  = fname.replace(\"-corr\",\"\")\n",
    "\n",
    "# print(\"Fichier de sortie: \", fout )\n",
    "\n",
    "f = open(fname, \"r\")\n",
    "txt = f.read()\n",
    " \n",
    "f.close()\n",
    "\n",
    "\n",
    "f2 = open(fout, \"w\")\n",
    "f2.write(re.sub(\"<CORRECTION>.*?(</CORRECTION>)\",\" TODO \",\\\n",
    "    txt, flags=re.DOTALL))\n",
    "f2.close()\n",
    "\n",
    "### </CORRECTION> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "902a52bcf4503a473db011f1937bdfe17613b08622219712e0110e48c4958c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
