{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook d'introduction à Scikit-learn\n",
    "\n",
    "1. Présentation très rapide des différents cadres de machine-learning\n",
    "2. Transposition dans l'univers sklearn (reposant lui-même sur numpy/matplotlib)\n",
    "3. Prise en main des outils\n",
    "\n",
    "# Plan:\n",
    "\n",
    "* [A. Données](#a-les-données)\n",
    "* [B. CLassifieurs (supervisés)](#b-classification-supervisée)\n",
    "    * [B.1 Mise en oeuvre](#b1-mise-en-oeuvre-des-modèles)\n",
    "    * [B.2 Evaluation, comparaison](#b2-evaluation--comparaison-de-modèles)\n",
    "    * [B.3. Analyse quali sur des données jouet](#b3-analyse-qualitative-sur-les-données-jouets)\n",
    "    * [B.4. Introspection des modèles](#b4-introspection-des-modèles)\n",
    "    * [B.5. Généricité vs spécificté des modèles](#b5-spécificité-des-modèles)\n",
    "    * [B.6. Focus sur l'arbre de décision](#b6-jouons-avec-un-arbre-de-décision)\n",
    "    * [B.7. Focus sur le SVM](#b7-jouons-avec-le-svm)\n",
    "* [C. Modèles de l'état de l'art (Forêt/XGB)](#c-modèles-de-létat-de-lart)\n",
    "    * [C.1. Mise en oeuvre](#c1-premières-expérimentations)\n",
    "    * [C.2. Introspection & explications](#c2-introspection-dans-un-modèle-linéaire-vs-xgboost-pondération-des-caractéristiques)\n",
    "* [D. Extension de scikit-learn](#d-extension-de-scikit-learn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# très classique\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Les données\n",
    "\n",
    "Quelques jeux de données classiques sont déjà dans la boite à outils, on va les utiliser pour aller plus vite. Evidemment, l'enjeux est ensuite de passer à des jeux de données plus proches de la réalité (e.g. challenge Kaggle) ou n'importe quel problème réel en important des données (csv, json, xls,...) à l'aide des fonctions existantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spécifique à scikit-learn\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# les données sont dans un dictionnaire python: \n",
    "# on regarde les clés\n",
    "print(\"Structuration des donbées: \",iris.keys())\n",
    "# puis les dimensions des valeurs d'intérêt\n",
    "print(\"Dimension: \",iris.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histoire de rendre les choses plus concretes: \n",
    "# tracé des deux premières variables (avec les couleurs en étiquettes)\n",
    "\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "\n",
    "plt.figure(facecolor='white')\n",
    "plt.scatter(X[:,0], X[:,1], c=Y) # on peut donner un vecteur de nombre pour les couleurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données jouets\n",
    "\n",
    "Afin de mieux comprendre la suite, on propose de travailler sur des données jouets, en 2D: ces données seront directement visualisables et permettent de comprendre le fonctionnement interne des classifieurs.\n",
    "\n",
    "**Attention** à toujours garder en tête le coté *factice* des données 2d et à faire l'effort mental de transposer vos conclusions en plus haute dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n   = 100\n",
    "sig = 1.5\n",
    "np.random.seed(42)  # reproductibilité\n",
    "X = np.random.randn(n,2)*sig\n",
    "Y = np.zeros(n)\n",
    "Y[n//2:]=1          # moitié des données y=0 / moitié y=1\n",
    "X[Y==0] += 2        # décalage des classes\n",
    "X[Y==1] -= 2\n",
    "\n",
    "plt.figure(facecolor='white')    # visu\n",
    "plt.scatter(X[:,0], X[:,1], c=Y)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# séparation des indices d'apprentissage et de test\n",
    "pcapp   = 0.7\n",
    "ind     = np.random.permutation(len(X))\n",
    "indapp  = ind[:int(pcapp*len(X))]\n",
    "indtest = ind[int(pcapp*len(X)):]\n",
    "Xapp,Yapp   = X[indapp],Y[indapp]\n",
    "Xtest,Ytest = X[indtest],Y[indtest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les données d'apprentissage et de test avec un code de forme différent\n",
    "# Classe 1 = jaune, Classe 2 = bleu\n",
    "# App = ronds, Test = étoile\n",
    "\n",
    "plt.figure(facecolor='white')\n",
    "# <CORRECTION>\n",
    "plt.scatter(X[indapp,0], X[indapp,1], c=Y[indapp])\n",
    "plt.scatter(X[indtest,0], X[indtest,1], c=Y[indtest],marker='*', edgecolors=\"r\")\n",
    "plt.grid()\n",
    "# </CORRECTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Classification supervisée\n",
    "\n",
    "Commençons par étudier quelques modèles classiques en classification supervisée... \n",
    "\n",
    "### B.1. Mise en oeuvre des modèles\n",
    "\n",
    "Il s'agit de programmation objet et d'héritage... Mais pour l'utilisateur, c'est surtout un ensemble de modèles facilement disponible sur l'étagère.\n",
    "\n",
    "1. Initialisation du modèle & des paramètres (=création du classifieur)\n",
    "2. Apprentissage sur les données d'entrainement (=`fit`)\n",
    "3. Inférence sur les données d'apprentissage ou de test (=`predict`)<BR>\n",
    "  ATTENTION: predict attend un ensemble de données, pas une seule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm,linear_model, naive_bayes\n",
    "\n",
    "# creation d'un modèle bayesien naïf\n",
    "mod = naive_bayes.GaussianNB() \n",
    "# apprentissage sur les données d'apprentissage\n",
    "mod.fit(Xapp, Yapp)\n",
    "# inférence, sur un individu (le premier point de test)\n",
    "yhat = mod.predict([Xtest[0]])      # attention, la fonction est\n",
    "                                    # prévue pour traiter un ensemble de points\n",
    "                                    # et pas une seule donnée\n",
    "                                    # d'où les [] supplémentaires\n",
    "                                    # => La fonction retourne une liste de prédictions\n",
    "\n",
    "print(\"comparaison entre prédiciton et vérité terrain: \", yhat, Y[indtest[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parfois on veut prédire une CLASSE, parfois on veut un SCORE\n",
    "# 1. classe => plus simple pour les métriques (e.g. tx bonne classif)\n",
    "# 2. score  => important pour la mesurer la confiance, la distance à la frontière etc...\n",
    "\n",
    "yhat  = mod.predict([Xtest[0]])   \n",
    "score = mod.predict_proba([Xtest[0]])   # predict_proba... Même pour les modèles non bayesien\n",
    "                                        # ATTENTION: un score par classe (dim != yhat)\n",
    "\n",
    "print(yhat, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Mini-exo</span> (rappels de numpy)\n",
    "\n",
    "1. Calculer à la main le taux de bonne classification à partir d'une sortie probabiliste\n",
    "2. En admettant un taux de rejet des points les plus ambigus (5%), que devient le taux de bonne classification sur les 95% restants?\n",
    "\n",
    "**Rappel**: il s'agit d'une technique de rejet qui peut être très utile en contexte opérationnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_prob = mod.predict_proba(Xtest)\n",
    "# calculer le taux de bonne classification par rapport à Ytest\n",
    "# <CORRECTION>\n",
    "tx = np.where(yhat_prob.argmax(1) == Ytest,1., 0).mean()\n",
    "print(tx)\n",
    "# </CORRECTION>\n",
    "\n",
    "# trouver les indices des 95% des points les moins ambigus\n",
    "# calculer le taux de bonne classification sur ces points\n",
    "# <CORRECTION>\n",
    "ind80 = np.argsort(np.abs(yhat_prob[:,0]-yhat_prob[:,1]))[int(.05*len(Ytest)):]\n",
    "tx = np.where(yhat_prob[ind80].argmax(1) == Ytest[ind80],1., 0).mean()\n",
    "print(tx)\n",
    "# </CORRECTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Mini-exo</span> Passage en plus grande dimension\n",
    "\n",
    "Le classifieur utilisé `naive_bayes.GaussianNB()` correspond à l'une des solutions envisagée pour les données USPS dans un des notebook précédent: vérifier que vous êtes capable d'évaluer ce classifieur sur les données USPS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. chargement des données\n",
    "import pickle as pkl\n",
    "data = pkl.load(open(\"data/usps.pkl\",'rb')) \n",
    "# data est un dictionnaire contenant les champs explicites X_train, X_test, Y_train, Y_test\n",
    "Xu_train = np.array(data[\"X_train\"],dtype=float) # changement de type pour éviter les problèmes d'affichage\n",
    "Xu_test = np.array(data[\"X_test\"],dtype=float)\n",
    "Yu_train = data[\"Y_train\"]\n",
    "Yu_test = data[\"Y_test\"]\n",
    "\n",
    "# 2. apprentissage du modèle\n",
    "# <CORRECTION>\n",
    "modu = naive_bayes.GaussianNB()\n",
    "modu.fit(Xu_train,Yu_train)\n",
    "# </CORRECTION>\n",
    "\n",
    "# 3. Eval: quel taux de bonne classification?\n",
    "# <CORRECTION>\n",
    "yuhat = modu.predict(Xu_test)\n",
    "tx = np.where(yuhat == Yu_test,1., 0).mean()\n",
    "print(tx)\n",
    "# </CORRECTION>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.2 Evaluation & comparaison de modèles\n",
    "\n",
    "Un des enjeux du machine learning consiste à choisir le modèle qui marche le mieux pour un problème donné.\n",
    "L'architecture de `sklearn` est particulièrement performante pour répondre à cette question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparaison simple de modèles\n",
    "mod1 = naive_bayes.GaussianNB()\n",
    "mod2 = svm.SVC()\n",
    "\n",
    "mod1.fit(Xapp, Yapp)\n",
    "mod2.fit(Xapp, Yapp)\n",
    "\n",
    "yhat1 = mod1.predict(Xtest)\n",
    "yhat2 = mod2.predict(Xtest)\n",
    "\n",
    "print(\"perf modèle 1 \", np.where(yhat1 == Ytest,1,0).mean())\n",
    "print(\"perf modèle 2 \", np.where(yhat2 == Ytest,1,0).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sélection des paramètres d'un modèle\n",
    "\n",
    "La plupart des modèles ont des hyper-paramètres qui impactent beaucoup les performances... cf exemple ci-dessous.\n",
    "Il faut donc comprendre aussi la sélection de modèle comme une manière d'optimiser les hyper-paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_SVM1 = svm.SVC(kernel=\"linear\", probability=True)   # proba pour les affichages avancés ci-dessous\n",
    "mod_SVM2 = svm.SVC(gamma = 10, probability=True)\n",
    "\n",
    "mod_SVM1.fit(Xapp, Yapp)\n",
    "mod_SVM2.fit(Xapp, Yapp)\n",
    "\n",
    "yhat1 = mod_SVM1.predict(Xtest)\n",
    "yhat2 = mod_SVM2.predict(Xtest)\n",
    "\n",
    "print(\"perf modèle 1 \", np.where(yhat1 == Ytest,1,0).mean())\n",
    "print(\"perf modèle 2 \", np.where(yhat2 == Ytest,1,0).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.3 Analyse qualitative sur les données jouets\n",
    "\n",
    "Traçons les frontières de décisions pour comprendre les modèles... Evidemment, on ne peut tracer ces fonctions qu'en 2D.\n",
    "\n",
    "Note 1: la fonction de tracé de la frontière est un peu complexe, pas besoin de comprendre en profondeur (ou alors demander au prof.)\n",
    "\n",
    "Note 2: la fonction est donnée... Mais pas dans le notebook: afin de rendre le code plus clair, les fonctions de tracé sont dans un module externe (= un répertoire avec des fichiers de code).\n",
    "\n",
    "1. Les modules sont (très) importants en python. Il faut apprendre à les utiliser, puis à en faire\n",
    "    * un répertoire contenant un fichier `__init__.py` (vide dans un premier temps)\n",
    "    * un ou plusieurs fichiers contenant des fonctions\n",
    "\n",
    "2. L'interface entre un notebook et un module peut être complexe: en effet, par défaut, les modifications du module ne sont pas prise en compte, il faut ajouter des options.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# répertoire outils\n",
    "# fichier frontiere\n",
    "# plusieurs fonctions dans le fichier\n",
    "from outils.frontiere import plot_frontiere\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cas d'usage\n",
    "\n",
    "plt.figure(figsize=(12,4), facecolor='white')\n",
    "plt.subplot(1,3,1) # indicage foireux hérité de matlab :)\n",
    "plot_frontiere(Xapp, Yapp, mod1)\n",
    "plt.scatter(Xapp[:,0], Xapp[:,1], c=Yapp)\n",
    "plt.title('Naive Bayes')\n",
    "plt.subplot(1,3,2)\n",
    "plot_frontiere(Xapp, Yapp, mod_SVM1)\n",
    "plt.scatter(Xapp[:,0], Xapp[:,1], c=Yapp)\n",
    "plt.title('SVC')\n",
    "plt.subplot(1,3,3)\n",
    "plot_frontiere(Xapp, Yapp, mod_SVM2)\n",
    "plt.scatter(Xapp[:,0], Xapp[:,1], c=Yapp)\n",
    "plt.title('SVC (2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les classifieurs qui possède la méthode `predict_proba` (tous ou presque tous... A condition d'avoir mis les bonnes options à la création), j'ai développé une méthode `plot_mesh` qui permet de voir la fonction de décision en 3D...\n",
    "\n",
    "1. Importer cette fonction de mon module (vérifier éventuellement son existance dans `frontiere.py`)\n",
    "1. Ouvrir une figure 3D (code donné ci-dessous)\n",
    "1. Utiliser la fonction. ATTENTION, la fonction ne marche que sur les classifieurs SVM :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. effectuer l'import correctement\n",
    "\n",
    "from outils.frontiere import *\n",
    "# 2. ouverture de la figure\n",
    "fig = plt.figure(facecolor='white', figsize=(10,8))\n",
    "ax = fig.add_subplot(projection='3d') # ATTENTION, il faut ouvrir une figure 3D pour avoir droit à ma fonction\n",
    "\n",
    "# 3. appel de la fonction\n",
    "plot_mesh(Xapp, Yapp, mod_SVM2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.4. Introspection des modèles\n",
    "\n",
    "Que valent les paramètres appris? Idéalement, que signifient-ils? \n",
    "\n",
    "<span style=\"color:red\"> ATTENTION: les modèles ont évidemment des paramètres spécifiques => trouver les paramètres à explorer = lire la documentation de chaque modèle</span>\n",
    "\n",
    "1. On passe par la documentation pour savoir quoi regarder: <BR>\n",
    "e.g. : https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
    "\n",
    "2. On va chercher les paramètre pour les afficher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes: 2 variables => 2 gaussiennes... Par classe \n",
    "\n",
    "print(mod1.sigma_) # ou .var_ si vous avez une version récente de sklearn\n",
    "print(mod1.theta_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Exercice] Dans les SVM, la régularisation fait que la solution ne repose que sur quelques points (les vecteurs supports). Faire en sorte d'afficher les points qui supportent la solution dans le cas linéaire:\n",
    "\n",
    "```mod = svm.SVC(kernel='linear')```\n",
    "\n",
    "<img src=fig/svm_support_1.png>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation des figures du cours (Hors sujet pour le TP)\n",
    "### <CORRECTION> ###\n",
    "from outils.frontiere import plot_mesh,plot_svm\n",
    "\n",
    "\n",
    "Xapp = Xapp[:20]\n",
    "Yapp = Yapp[:20]\n",
    "\n",
    "mod_SVM1 = svm.SVC(kernel=\"linear\")\n",
    "mod_SVM2 = svm.SVC(gamma = 10, C=10)\n",
    "mod_SVM3 = svm.SVC(gamma = 1, C=1e9)\n",
    "\n",
    "\n",
    "\n",
    "mod_SVM1.fit(Xapp, Yapp)\n",
    "mod_SVM2.fit(Xapp, Yapp)\n",
    "mod_SVM3.fit(Xapp, Yapp)\n",
    "\n",
    "\n",
    "support1 = mod_SVM1.support_\n",
    "support2 = mod_SVM2.support_\n",
    "support3 = mod_SVM3.support_\n",
    "\n",
    "plt.figure()\n",
    "plot_svm(Xapp, Yapp, mod_SVM1)\n",
    "plt.scatter(Xapp[:,0], Xapp[:,1], c=Yapp)\n",
    "plt.scatter(Xapp[support1,0], Xapp[support1,1], edgecolor='k',marker='s',s=100,facecolors=\"none\")\n",
    "plt.savefig(\"fig/svm_marge.png\")\n",
    "\n",
    "plt.figure()\n",
    "plot_frontiere(Xapp, Yapp, mod_SVM1)\n",
    "plt.scatter(Xapp[:,0], Xapp[:,1], c=Yapp)\n",
    "plt.scatter(Xapp[support1,0], Xapp[support1,1], edgecolor='k',marker='s',s=100,facecolors=\"none\")\n",
    "plt.savefig(\"fig/svm_support_1.png\")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "plot_mesh(Xapp, Yapp, mod_SVM1, ax)\n",
    "ax.scatter(Xapp[:,0], Xapp[:,1], 0, c=Yapp)\n",
    "ax.scatter(Xapp[support1,0], Xapp[support1,1], 0, edgecolor='k',marker='s',s=100,facecolors=\"none\")\n",
    "plt.savefig(\"fig/svm_support_3d_1.png\")\n",
    "\n",
    "\n",
    "# print(support1)\n",
    "# plt.figure()\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,3,1) # indicage foireux hérité de matlab :)\n",
    "plot_frontiere(Xapp, Yapp, mod_SVM1)\n",
    "plt.scatter(Xapp[:,0], Xapp[:,1], c=Yapp)\n",
    "plt.scatter(Xapp[support1,0], Xapp[support1,1], edgecolor='k',marker='s',s=100,facecolors=\"none\")\n",
    "\n",
    "plt.title('SVC linéaire')\n",
    "plt.subplot(1,3,3)\n",
    "plot_frontiere(Xapp, Yapp, mod_SVM2)\n",
    "plt.scatter(Xapp[:,0], Xapp[:,1], c=Yapp)\n",
    "plt.scatter(Xapp[support2,0], Xapp[support2,1], edgecolor='k',marker='s',s=100,facecolors=\"none\")\n",
    "\n",
    "plt.title('SVC gaussien')\n",
    "plt.subplot(1,3,2)\n",
    "plot_frontiere(Xapp, Yapp, mod_SVM3)\n",
    "plt.scatter(Xapp[:,0], Xapp[:,1], c=Yapp)\n",
    "plt.scatter(Xapp[support3,0], Xapp[support3,1], edgecolor='k',marker='s',s=100,facecolors=\"none\")\n",
    "\n",
    "plt.title('SVC gaussien')\n",
    "plt.savefig(\"fig/svm_support2.png\")\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(18,6))\n",
    "# ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax = fig.add_subplot(1,3,1,projection='3d')\n",
    "plot_mesh(Xapp, Yapp, mod_SVM1, ax)\n",
    "ax.scatter(Xapp[:,0], Xapp[:,1], 0, c=Yapp)\n",
    "ax.scatter(Xapp[support1,0], Xapp[support1,1], 0, edgecolor='k',marker='s',s=100,facecolors=\"none\")\n",
    "\n",
    "ax = fig.add_subplot(1,3,3,projection='3d')\n",
    "plot_mesh(Xapp, Yapp, mod_SVM2, ax)\n",
    "ax.scatter(Xapp[:,0], Xapp[:,1],0, c=Yapp)\n",
    "ax.scatter(Xapp[support2,0], Xapp[support2,1],0, edgecolor='k',marker='s',s=100,facecolors=\"none\")\n",
    "\n",
    "ax = fig.add_subplot(1,3,2,projection='3d')\n",
    "plot_mesh(Xapp, Yapp, mod_SVM3, ax)\n",
    "ax.scatter(Xapp[:,0], Xapp[:,1], c=Yapp)\n",
    "ax.scatter(Xapp[support3,0], Xapp[support3,1],0, edgecolor='k',marker='s',s=100,facecolors=\"none\")\n",
    "\n",
    "\n",
    "plt.savefig(\"fig/svm_support_3d.png\")\n",
    "\n",
    "### </CORRECTION> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.5. Spécificité des modèles\n",
    "\n",
    "Afin de faciliter leur utilisation, tous les modèles disposent de `fit` et `predict` (et aussi de `score`)... Mais les modèles peuvent aussi avoir des spécificités qui apparaissent dans la documentation. \n",
    "> <span style=\"color:magenta\"> Vous devez exploiter la généricité des architectures ET la spécificité des modèles :) </span>\n",
    "\n",
    "Par exemple, sur le modèle NB gaussien, il est possible d'obtenir la vraisemblance de chaque point évalué pour chaque classe, ce qui ouvre des perspectives applicatives telles que le rejet des points ambigus.\n",
    "\n",
    "Vous devriez obenir quelque chose de la forme:\n",
    "<img src=\"./fig/vraisemblance.png\">\n",
    "\n",
    "Note: évidemment, la vraisemblance n'est tracée que pour l'une des deux classes.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher la vraisemblance des points en couleur\n",
    "\n",
    "### <CORRECTION> ###\n",
    "\n",
    "lv=mod1.predict_proba(Xapp)\n",
    "print(lv.shape)\n",
    "\n",
    "plt.figure(facecolor='white')\n",
    "plt.scatter(Xapp[:,0], Xapp[:,1], c=lv[:,0])\n",
    "plt.colorbar()\n",
    "\n",
    "plt.savefig(\"fig/vraisemblance.png\")\n",
    "\n",
    "### </CORRECTION> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.6. Jouons avec un arbre de décision\n",
    "\n",
    "Les arbres de décision ont un statut particulier: à cheval entre l'apprentissage symbolique et statistique... Un petit exercice autour de ce modèle.\n",
    "\n",
    "La plupart des réponses se trouvent [ici](https://scikit-learn.org/stable/modules/tree.html)\n",
    "\n",
    "Voici les questions: \n",
    "1. Construire le modèle par défaut et l'entrainer\n",
    "2. Visualiser la frontière de décision puis l'algorithme de décision... Et réfléchir à la manière dont fonctionne cette décision. Pourquoi considère-t-on que ce modèle est plus explicable que d'autres?\n",
    "\n",
    "Note: vous devez obtenir quelque chose de la forme : \n",
    "\n",
    "<img src=\"fig/tree_decision_c.png\"> <img src=\"fig/tree_decision_2d.png\"><BR>\n",
    "Bonus: trouver le nom de l'option qui colorie les branche de l'arbre en fonction de la classe d'affectation.\n",
    "\n",
    "\n",
    "3. Entrainer et visualiser un arbre de profondeur limitée à 1 puis 2 et analyser le résultat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# Construction & apprentissage du modèle\n",
    "### <CORRECTION> ###\n",
    "\n",
    "mod = tree.DecisionTreeClassifier()\n",
    "mod.fit(Xapp,Yapp)\n",
    "\n",
    "### </CORRECTION> ###\n",
    "\n",
    "# visualisation du modèle\n",
    "plt.figure(facecolor='white')\n",
    "plot_frontiere(Xapp, Yapp, mod) # si votre modèle ne s'appelle pas mod => mettre à jour\n",
    "plt.scatter(Xapp[:,0], Xapp[:,1], c=Yapp)\n",
    "# plt.savefig('fig/tree_decision_2d.png')\n",
    "\n",
    "# dessin de l'algorithme de décision\n",
    "### <CORRECTION> ###\n",
    "plt.figure(facecolor='white')\n",
    "tree.plot_tree(mod, filled=True)\n",
    "#plt.savefig('fig/tree_decision.png')\n",
    "### </CORRECTION> ###\n",
    "\n",
    "# Entrainer et visualiser un arbre de profondeur 1 puis 2\n",
    "### <CORRECTION> ###\n",
    "\n",
    "mod = tree.DecisionTreeClassifier(max_depth=1)\n",
    "mod.fit(Xapp,Yapp)\n",
    "mod2 = tree.DecisionTreeClassifier(max_depth=2)\n",
    "mod2.fit(Xapp,Yapp)\n",
    "plt.figure(facecolor='white',figsize=[10,5])\n",
    "plt.subplot(1,2,1)\n",
    "plot_frontiere(Xapp, Yapp, mod) # si votre modèle ne s'appelle pas mod => mettre à jour\n",
    "plt.scatter(Xapp[:,0], Xapp[:,1], c=Yapp)\n",
    "plt.subplot(1,2,2)\n",
    "plot_frontiere(Xapp, Yapp, mod2) # si votre modèle ne s'appelle pas mod => mettre à jour\n",
    "plt.scatter(Xapp[:,0], Xapp[:,1], c=Yapp)\n",
    "plt.figure(facecolor='white',figsize=[10,5])\n",
    "plt.subplot(1,2,1)\n",
    "tree.plot_tree(mod, filled=True)\n",
    "plt.subplot(1,2,2)\n",
    "tree.plot_tree(mod2, filled=True)\n",
    "#plt.savefig('fig/tree_decision_1vs2.png')\n",
    "### </CORRECTION> ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.7. Jouons avec le SVM\n",
    "\n",
    "Comparer un classifieur SVM avec un noyau linéaire et un noyau gaussien.\n",
    "\n",
    "1. Tracer les frontières de décision\n",
    "1. Jouer avec la largeur de bande des gaussiennes\n",
    "1. Mettre en évidence le phénomène de sur-apprentissage (très rapide avec les gaussiennes trop serrées)\n",
    "\n",
    "Afin de tirer parti des capacités non linéaire des SVM, nous allons travailler sur des données non séparable linéairement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "centers = [[float(i),float(j)] for i in range(5) for j in range(5)]\n",
    "print(centers)\n",
    "clusters_std = 0.2\n",
    "X, y = make_blobs(n_samples=100, centers=centers, cluster_std=clusters_std,  n_features=2,   random_state=0)\n",
    "y = (y % 2)*2 - 1 \n",
    "\n",
    "print(X.shape)\n",
    "plt.figure(facecolor='white')\n",
    "plt.scatter(X[:,0], X[:,1], c=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C Modèles de l'état de l'art\n",
    "\n",
    "Si les approches bayesiennes sont rapides et que les SVM forment une référence solide, il faut admettre aujourd'hui l'efficacité redoutable des approches ensemblistes sur un grand nombre de taches.\n",
    "\n",
    "Parmi toutes les approches de bagging / boosting, deux modèles s'illustrent particulièrement: les forêts aléatoires et le gradient boosting.\n",
    "\n",
    "1. Forêt aléatoire : [lien](https://en.wikipedia.org/wiki/Random_forest)\n",
    "    - les arbres comportent une part aléatoire dans leur construction (ils fonctionnent sur un sous-ensemble de variables)... Ils sont donc individuellement assez faibles\n",
    "    - le mécanisme de vote rend l'ensemble de la forêt très efficace.\n",
    "    - [lien vers le classifieur sklearn](https://scikit-learn.org/stable/modules/ensemble.html?highlight=random+forest#forests-of-randomized-trees)\n",
    "\n",
    "\n",
    "2. Gradient boosting\n",
    "    - très grossièrement: il s'agit d'une forêt où les arbres sont ajoutés itérativement pour réduire les erreurs de forêt à l'itération précédente.\n",
    "    - l'implémentation sklearn est intéressante [lien](https://scikit-learn.org/stable/modules/ensemble.html?highlight=random+forest#gradient-tree-boosting)... Mais la plus efficace (rapide + hardware acceleration + super paramètres par défaut + interprétation) est XGboost [lien](https://xgboost.readthedocs.io/en/stable/)\n",
    "    - il existe une interface sklearn pour XGBoost... Ca s'utilise donc comme tous les autres modèles\n",
    "\n",
    "<img src=\"fig/xgboost_the_things.jpg\">\n",
    "\n",
    "## C.1. Premières expérimentations\n",
    "\n",
    "Pour les deux modèles:\n",
    "1. Entrainer le modèle de base\n",
    "2. Visualiser la frontière de décision\n",
    "3. Essayer de jouer avec les paramètres: au moins le nombre d'arbres + leur profondeur\n",
    "4. [OPT] Reprendre les données USPS et comparer les performances de ces approches par rapport aux classifieurs bayesien naïf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-générer des données (avec sklearn)\n",
    "# 1. Trouver la bonne fonction\n",
    "# 2. Trouver la séparation des données app/test\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "centers = [[-2.0, -2.0], [2.0, 2.0]]\n",
    "clusters_std = [1.5, 1.5]\n",
    "X, y = make_blobs(n_samples=100, centers=centers, cluster_std=clusters_std,  n_features=2,   random_state=0) # 100 pts, 2classes, 2dim \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "plt.figure(facecolor='white')\n",
    "plt.scatter(X_train[:,0],X_train[:,1],c=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Foret aléatoire sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "mod =  RandomForestClassifier()\n",
    "mod.fit(X_train,y_train)\n",
    "\n",
    "# Evaluation quantitative\n",
    "yhat = mod.predict(X_test)\n",
    "print(\"perf modèle RF\", np.where(yhat == y_test,1,0).mean())\n",
    "\n",
    "# Trace de la frontière\n",
    "plt.figure(facecolor='white')\n",
    "plot_frontiere(X_train, y_train, mod) # si votre modèle ne s'appelle pas mod => mettre à jour\n",
    "plt.scatter(X_train[:,0], X_train[:,1], c=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information de base sur le modèle appris:\n",
    "print(\"nb arbres : \", mod.n_estimators)\n",
    "print(\"profondeur des arbres : \", mod.max_depth) # on a laissé le pararmètre par défaut... Comment trouver cette valeur?\n",
    "print(\"profondeur des arbres (bis, pour les 10 premiers): \", [mod.estimators_[i].get_depth() for i in range(10)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeu avce les paramètre de la foret aléatoire (code donné)\n",
    "\n",
    "mod1 =  RandomForestClassifier(max_depth=1,n_estimators=5) # tres simple\n",
    "mod1.fit(X_train,y_train)\n",
    "\n",
    "mod2 =  RandomForestClassifier(max_depth=10,n_estimators=100) # tres simple\n",
    "mod2.fit(X_train,y_train)\n",
    "\n",
    "# Trace de la frontière\n",
    "plt.figure(figsize=[8,4])\n",
    "plt.subplot(1,2,1)\n",
    "plot_frontiere(X_train, y_train, mod1) \n",
    "plt.scatter(X_train[:,0], X_train[:,1], c=y_train)\n",
    "plt.subplot(1,2,2)\n",
    "plot_frontiere(X_train, y_train, mod2,step=40) \n",
    "plt.scatter(X_train[:,0], X_train[:,1], c=y_train)\n",
    "\n",
    "# N'hésitez pas à complexifier les données et relncer de bout de code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGboost\n",
    "\n",
    "import xgboost as xgb # !pip install xgboost # en cas de besoin\n",
    "\n",
    "bst = xgb.XGBClassifier().fit(X_train,y_train) # pour passer par l'interface sklearn\n",
    "# make prediction\n",
    "yhat = bst.predict(X_test)\n",
    "\n",
    "print(\"perf modèle XGB\", np.where(yhat == y_test,1,0).mean())\n",
    "\n",
    "# Trace de la frontière\n",
    "plt.figure(facecolor='white')\n",
    "plot_frontiere(X_train, y_train, bst) # si votre modèle ne s'appelle pas mod => mettre à jour\n",
    "plt.scatter(X_train[:,0], X_train[:,1], c=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C.2 Introspection dans un modèle linéaire vs XGBoost: pondération des caractéristiques\n",
    "\n",
    "Si on crée le jeu de données jouet suivant:\n",
    "\n",
    "$$X = \\begin{pmatrix}  x_{11}& x_{12} & x_{13} \\sim \\mathcal N(0,\\sigma) & \\ldots & x_{1d} \\sim \\mathcal N(0,\\sigma) \\\\\n",
    "x_{21}& x_{22} & x_{23} \\sim \\mathcal N(0,\\sigma) & \\ldots & x_{2d} \\sim \\mathcal N(0,\\sigma) \\\\\n",
    "\\vdots& \\vdots & \\vdots & \\ddots &\\vdots \\\\\n",
    "x_{n1}& x_{n2} & x_{n3} \\sim \\mathcal N(0,\\sigma) & \\ldots & x_{nd} \\sim \\mathcal N(0,\\sigma) \\\\\n",
    "\\end{pmatrix} ,\\qquad\n",
    "Y = \\begin{pmatrix}  y_{1} \\\\\n",
    "y_{2}\\\\\n",
    "\\vdots\\\\\n",
    "y_{n} \\\\\n",
    "\\end{pmatrix} ,\\qquad y_i\\in\\{0,1\\}\n",
    "$$\n",
    "\n",
    "Il s'agit d'un problème où les deux premières colonnes ont du sens et dans lesquelles on a ajouté des colonnes de bruit blanc. La visualisation des deux premières colonnes avec les étiquettes donne classiquement: \n",
    "\n",
    "<img src=\"fig/data2d.png\"> \n",
    "\n",
    "La question qui se pose:\n",
    "> <span style=\"color:magenta\"> Est-on capable de donner un score aux différentes colonnes, une fois l'apprentissage effectué?</span>\n",
    "\n",
    "1. Avec les modèles linéaire, la réponse est triviale: il suffit de regarder les coefficients du classifieur\n",
    "1. Avec une approche ensembliste, c'est possible aussi et c'est déjà implémenté: il suffit d'aller chercher les bonnes méthodes\n",
    "\n",
    "Pour l'explication des combinaisons qui sont calculées (et les risques de sur-interprétation): [lien](https://towardsdatascience.com/be-careful-when-interpreting-your-features-importance-in-xgboost-6e16132588e7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# données\n",
    "centers = [[-2.0, -2.0], [2.0, 2.0]]\n",
    "clusters_std = [1.5, 1.5]\n",
    "X, y = make_blobs(n_samples=50, centers=centers, cluster_std=clusters_std,  n_features=2,   random_state=0) # 100 pts, 2classes, 2dim \n",
    "\n",
    "# ajout de bruit\n",
    "ndim_noise = 20\n",
    "Noise = np.random.randn(len(X), ndim_noise)*clusters_std[0]\n",
    "Xn = np.concatenate((X,Noise), axis=1)\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xn, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(facecolor='white')\n",
    "plt.scatter(X[:,0],X[:,1],c=y)\n",
    "plt.xlabel(\"$X_1$\")\n",
    "plt.ylabel(\"$X_2$\")\n",
    "\n",
    "# plt.savefig(\"fig/data2d.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Apprentissage d'un modèle lineaire\n",
    "mod1 = LogisticRegression()\n",
    "mod2 = xgb.XGBClassifier()\n",
    "\n",
    "mod1.fit(X_train,y_train)\n",
    "mod2.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le modèle linéaire, vous devez être capable :\n",
    "1. d'aller chercher les paramètres\n",
    "1. de tracer un diagramme `plt.bar` de ces paramètres \n",
    "    - à vous de choisir si vous optez pour la valeur absolue ou pas: les deux choix sont argumentables\n",
    "    - vous ferez attention à la dimension des paramètres\n",
    "\n",
    "<img src=\"fig/bar_mod_lin.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage des poids associées aux caractéristiques du problème\n",
    "\n",
    "### <CORRECTION> ###\n",
    "\n",
    "#print(np.arange(X_train.shape[1]),mod1.coef_)\n",
    "\n",
    "plt.figure(facecolor='white')\n",
    "plt.bar(np.arange(X_train.shape[1]), mod1.coef_[0])\n",
    "plt.title('Poids (Intercept = '+str(mod1.intercept_)+')')\n",
    "# plt.savefig(\"fig/bar_mod_lin.png\")\n",
    "\n",
    "### </CORRECTION> ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire la même chose XGBoost en allant chercher la (les) fonction(s) utile(s) dans la documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Extension de scikit-learn\n",
    "\n",
    "Selon les principes de la programmation objet, vous pouvez définir votre propre classifieur et utiliser ensuite toutes les fonctions qui attendent un classifieur (validation croisée, grid search...)\n",
    "\n",
    "Voici un code minimaliste illustrant l'héritage en python (très simple) dans le cas sklearn:\n",
    "\n",
    "Pour plus de détails: [lien](https://scikit-learn.org/stable/developers/develop.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# un classifieur à poids fixes (un peu absurde donc...) Mais qui montre comment ça marche\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class LinearFixClassifier(BaseEstimator, ClassifierMixin):\n",
    "     def __init__(self, data_dim=2): # on  a besoin de connaitre la dimension des données\n",
    "         self.data_dim = data_dim # il faut stocker tous les attributs pour la sérialisation des modèles.\n",
    "         self.w = np.random.randn(data_dim) # init\n",
    "\n",
    "     def fit(self, X, y):\n",
    "         # On a rien besoin de faire dans notre cas...\n",
    "         # Store the classes seen during fit\n",
    "         self.classes_ = np.unique(y)\n",
    "         # on stocke tout pour simplifier les choses après (fonction score)   \n",
    "         self.X_ = X\n",
    "         self.y_ = y\n",
    "         # Return the classifier\n",
    "         return self\n",
    "\n",
    "     def predict(self, X): # dans le cas binaire seulement\n",
    "\n",
    "         # Check if fit has been called\n",
    "         # check_is_fitted(self)\n",
    "\n",
    "         # Input validation\n",
    "         # X = check_array(X)\n",
    "         \n",
    "         # mon classifieur sort dans -1,1 et je remets ensuite les étiquette par rapport aux y\n",
    "         return np.where(X@self.w > 0, self.y_[0] , self.y_[1] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vous de vérifier que vous pouvez invoquer une validation croisée sur ce classifier !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# données\n",
    "centers = [[-2.0, -2.0], [2.0, 2.0]]\n",
    "clusters_std = [1.5, 1.5]\n",
    "X, y = make_blobs(n_samples=50, centers=centers, cluster_std=clusters_std,  n_features=2,   random_state=0) # 100 pts, 2classes, 2dim \n",
    "\n",
    "mod = LinearFixClassifier(2)\n",
    "mod.fit(X,y)\n",
    "yhat = mod.predict(X)\n",
    "\n",
    "print(yhat)\n",
    "\n",
    "# ajouter de la validation croisée (plus ambitieux => Une autre fonction, que je ne connais pas, va utiliser mon objet !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "n_fold = 5\n",
    "scores = cross_val_score(mod, X, y, cv=n_fold, scoring='accuracy') # tout est caché dedans :)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Annexe: transformation du notebook en version étudiante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### <CORRECTION> ###\n",
    "import re\n",
    "# transformation de cet énoncé en version étudiante\n",
    "\n",
    "fname = \"1-notebook-intro-corr.ipynb\" # ce fichier\n",
    "fout  = fname.replace(\"-corr\",\"\")\n",
    "\n",
    "# print(\"Fichier de sortie: \", fout )\n",
    "\n",
    "f = open(fname, \"r\")\n",
    "txt = f.read()\n",
    "\n",
    "f.close()\n",
    "\n",
    "\n",
    "f2 = open(fout, \"w\")\n",
    "f2.write(re.sub(\"<CORRECTION>.*?(</CORRECTION>)\",\" TODO \",\\\n",
    "    txt, flags=re.DOTALL))\n",
    "f2.close()\n",
    "\n",
    "### </CORRECTION> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "902a52bcf4503a473db011f1937bdfe17613b08622219712e0110e48c4958c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
